{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f69d9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import io\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from collections import defaultdict\n",
    "import pdfplumber # 이미지 추출을 위해 유지\n",
    "import filetype\n",
    "import camelot # 테이블 추출을 위해 추가\n",
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b36c9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계: 미디어 정보 미리 추출 중 (이미지: pdfplumber, 테이블: camelot)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 0개의 이미지 정보를 찾았습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 2개의 테이블 정보를 찾았습니다.\n",
      "2단계: unstructured로 문서 구조 분석 중 (hi_res 전략 사용)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3단계: 텍스트, 테이블, 이미지를 통합하고 AI로 내용을 보강합니다...\n",
      "  - 테이블 요약 생성 요청...\n",
      "  - 요약 생성 완료: 이 표는 특정 기간에 따른 신청 시기와 지급 비율에 대...\n",
      "  - 테이블 요약 생성 요청...\n",
      "  - 요약 생성 완료: 주어진 표는 연구 분야의 인건비 지급 기준과 자격 기준...\n",
      "4단계: 최종 결과 정리 및 저장...\n",
      "\n",
      "--- 작업 완료 ---\n"
     ]
    }
   ],
   "source": [
    "# --- 1. AI 클라이언트 및 유틸리티 함수 정의 (기존과 동일) ---\n",
    "client = OpenAI() # API 키는 환경 변수에 설정 권장\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def generate_image_description(image_path):\n",
    "    print(f\"  - 이미지 설명 생성 요청: {os.path.basename(image_path)}\")\n",
    "    base64_image = encode_image_to_base64(image_path)\n",
    "    image_ext = os.path.splitext(image_path)[1].lstrip('.')\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\",\n",
    "                   \"content\": [{\"type\": \"text\", \n",
    "                                \"text\": \"이 이미지는 무엇에 관한 것인가요? RAG 시스템에서 검색될 것을 가정하고, 이미지의 핵심 내용을 한글로 설명해주세요.\"}, \n",
    "                               {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/{image_ext};base64,{base64_image}\"}}]}],\n",
    "        max_tokens=200\n",
    "    )\n",
    "    description = response.choices[0].message.content.strip()\n",
    "    print(f\"  - 설명 생성 완료: {description[:30]}...\")\n",
    "    return description\n",
    "\n",
    "def generate_table_summary(table_csv_str):\n",
    "    if len(table_csv_str) > 4000:\n",
    "        table_csv_str = table_csv_str[:4000]\n",
    "    print(\"  - 테이블 요약 생성 요청...\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"system\",\n",
    "                   \"content\": \"당신은 데이터 분석가입니다. 주어진 표 데이터를 보고, 표의 핵심 내용을 한글 문장으로 요약하는 역할을 맡았습니다.\"},\n",
    "                  {\"role\": \"user\", \"content\": f\"다음은 CSV 형식의 표 데이터입니다. 이 표가 어떤 정보를 담고 있으며, 주요 특징이 무엇인지 요약해주세요.\\n\\n--- 데이터 시작 ---\\n{table_csv_str}\\n--- 데이터 끝 ---\"}],\n",
    "        max_tokens=300\n",
    "    )\n",
    "    summary = response.choices[0].message.content.strip()\n",
    "    print(f\"  - 요약 생성 완료: {summary[:30]}...\")\n",
    "    return summary\n",
    "\n",
    "# --- 2. AI 기능이 통합된 처리 함수 (camelot 데이터 형식에 맞게 수정) ---\n",
    "\n",
    "def process_table_with_ai_camelot(table_df, output_dir, page_num, table_index):\n",
    "    \"\"\"camelot으로 추출한 테이블 DataFrame을 처리하고 AI 요약을 생성합니다.\"\"\"\n",
    "    try:\n",
    "        df = table_df\n",
    "        table_filename = f\"p{page_num}_tbl{table_index}.csv\"\n",
    "        table_path = os.path.join(output_dir, \"tables\", table_filename)\n",
    "        df.to_csv(table_path, index=False, encoding=\"utf-8-sig\")\n",
    "        \n",
    "        # AI 요약을 위해 DataFrame을 CSV 문자열로 변환\n",
    "        csv_string = df.to_csv(index=False)\n",
    "        description = generate_table_summary(csv_string)\n",
    "        \n",
    "        return {\"path\": table_path, \"page\": page_num, \"dataframe\": df, \"description\": description}\n",
    "    except Exception as e:\n",
    "        print(f\"  - 테이블 처리 중 오류 발생: {e}\")\n",
    "        return None\n",
    "\n",
    "# process_image_with_ai 함수는 기존과 동일하게 pdfplumber를 사용하므로 변경 없음\n",
    "def process_image_with_ai(image_data, output_dir, page_num, image_index):\n",
    "    try:\n",
    "        image_bytes = image_data['stream'].get_data()\n",
    "        kind = filetype.guess(image_bytes)\n",
    "        image_ext = kind.extension if kind else \"png\"\n",
    "        image_filename = f\"p{page_num}_img{image_index}.{image_ext}\"\n",
    "        image_path = os.path.join(output_dir, \"images\", image_filename)\n",
    "        with open(image_path, \"wb\") as img_file:\n",
    "            img_file.write(image_bytes)\n",
    "        description = generate_image_description(image_path)\n",
    "        return {\"path\": image_path, \"page\": page_num, \"description\": description}\n",
    "    except Exception as e:\n",
    "        print(f\"  - 이미지 처리 중 오류 발생: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 3. camelot을 사용하도록 수정한 메인 함수 ---\n",
    "\n",
    "def create_integrated_markdown_from_camelot(pdf_path):\n",
    "    output_dir = os.path.basename(pdf_path).split(\".\")[0]\n",
    "    os.makedirs(os.path.join(output_dir, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"tables\"), exist_ok=True)\n",
    "\n",
    "    # 1단계: pdfplumber로 이미지, camelot으로 테이블 미리 추출\n",
    "    print(\"1단계: 미디어 정보 미리 추출 중 (이미지: pdfplumber, 테이블: camelot)...\")\n",
    "    \n",
    "    # pdfplumber로 이미지 추출\n",
    "    images_by_page = defaultdict(list)\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            images_by_page[page.page_number].extend(page.images)\n",
    "    print(f\"총 {sum(len(v) for v in images_by_page.values())}개의 이미지 정보를 찾았습니다.\")\n",
    "\n",
    "    # camelot으로 테이블 추출\n",
    "    # flavor='lattice'는 선이 있는 표에 적합, 선이 없는 표는 'stream' 사용\n",
    "    tables_by_page = defaultdict(list)\n",
    "    try:\n",
    "        tables = camelot.read_pdf(pdf_path, pages='all', flavor='lattice', suppress_stdout=True)\n",
    "        for table in tables:\n",
    "            tables_by_page[table.page].append(table.df)\n",
    "        print(f\"총 {sum(len(v) for v in tables_by_page.values())}개의 테이블 정보를 찾았습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Camelot으로 테이블 추출 중 오류 발생: {e}\")\n",
    "\n",
    "    # 2단계: unstructured로 PDF 요소 순서대로 파티셔닝 (기존과 동일)\n",
    "    print(\"2단계: unstructured로 문서 구조 분석 중 (hi_res 전략 사용)...\")\n",
    "    elements = partition_pdf(filename=pdf_path, infer_table_structure=True, strategy=\"hi_res\")\n",
    "\n",
    "    # 3단계: 요소 순회하며 최종 마크다운 및 데이터 생성\n",
    "    print(\"3단계: 텍스트, 테이블, 이미지를 통합하고 AI로 내용을 보강합니다...\")\n",
    "    final_markdown_parts = []\n",
    "    extracted_tables = []\n",
    "    extracted_images = []\n",
    "    page_counters = defaultdict(lambda: {'tables': 0, 'images': 0})\n",
    "\n",
    "    for el in elements:\n",
    "        page_num = el.metadata.page_number\n",
    "        \n",
    "        if \"unstructured.documents.elements.Table\" in str(type(el)):\n",
    "            table_index = page_counters[page_num]['tables']\n",
    "            if table_index < len(tables_by_page[page_num]):\n",
    "                # camelot이 추출한 DataFrame을 처리\n",
    "                raw_table_df = tables_by_page[page_num][table_index]\n",
    "                table_data = process_table_with_ai_camelot(raw_table_df, output_dir, page_num, table_index)\n",
    "                if table_data:\n",
    "                    placeholder = f\"\\n\\n[[-- TABLE: Page {page_num}, Index {table_index} | Path: {table_data['path']} --]]\\n**표 요약:** {table_data['description']}\\n\\n\"\n",
    "                    final_markdown_parts.append(placeholder)\n",
    "                    extracted_tables.append(table_data)\n",
    "                    page_counters[page_num]['tables'] += 1\n",
    "            \n",
    "        elif \"unstructured.documents.elements.Image\" in str(type(el)):\n",
    "            image_index = page_counters[page_num]['images']\n",
    "            if image_index < len(images_by_page[page_num]):\n",
    "                # pdfplumber가 추출한 이미지 처리\n",
    "                raw_image_data = images_by_page[page_num][image_index]\n",
    "                image_data = process_image_with_ai(raw_image_data, output_dir, page_num, image_index)\n",
    "                if image_data:\n",
    "                    relative_path = os.path.relpath(image_data['path'], output_dir).replace(os.sep, '/')\n",
    "                    md_link = f\"\\n\\n![{image_data['description']}]({relative_path})\\n\\n\"\n",
    "                    final_markdown_parts.append(md_link)\n",
    "                    extracted_images.append(image_data)\n",
    "                    page_counters[page_num]['images'] += 1\n",
    "        \n",
    "        else:\n",
    "            final_markdown_parts.append(el.text)\n",
    "\n",
    "    # 4단계: 최종 결과 정리 및 저장 (기존과 동일)\n",
    "    print(\"4단계: 최종 결과 정리 및 저장...\")\n",
    "    final_markdown = \"\\n\\n\".join(final_markdown_parts)\n",
    "    output_filename = os.path.join(output_dir, \"integrated_markdown_camelot.md\")\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(final_markdown)\n",
    "    \n",
    "    print(\"\\n--- 작업 완료 ---\")\n",
    "    return {\n",
    "        \"output_dir\": output_dir,\n",
    "        \"integrated_markdown_file\": output_filename,\n",
    "        \"images\": extracted_images,\n",
    "        \"tables\": extracted_tables,\n",
    "        \"integrated_markdown_content\": final_markdown,\n",
    "    }\n",
    "\n",
    "# --- 코드 실행 예제 ---\n",
    "pdf_path = \"datasets/manual.pdf\" # 실제 PDF 파일 경로로 변경해주세요.\n",
    "extracted_data = create_integrated_markdown_from_camelot(pdf_path)\n",
    "\n",
    "# # 결과 확인\n",
    "# print(f\"\\nAI 요약/설명이 포함된 통합 마크다운 파일이 '{extracted_data['integrated_markdown_file']}'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d63fb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [],\n",
      " 'integrated_markdown_content': 'Ⅴ 사업비 집행 및 정산지침\\n'\n",
      "                                '\\n'\n",
      "                                'OE\\n'\n",
      "                                '\\n'\n",
      "                                '사업비 지급 및 집행기간\\n'\n",
      "                                '\\n'\n",
      "                                '□ 사업비 지급\\n'\n",
      "                                '\\n'\n",
      "                                '\\n'\n",
      "                                '\\n'\n",
      "                                '[[-- TABLE: Page 1, Index 0 | Path: '\n",
      "                                'manual\\\\tables\\\\p1_tbl0.csv --]]\\n'\n",
      "                                '**표 요약:** 이 표는 특정 기간에 따른 신청 시기와 지급 비율에 대한 정보를 '\n",
      "                                \"담고 있습니다. 각 분기별로 지급 비율이 다르게 나타나며, '협약 체결 시'에는 \"\n",
      "                                \"20%, '협약 체결 후 2개월 이내'에서는 46%의 지급 비율이 있는 반면, \"\n",
      "                                \"'중간 평가 후 1개월 이내'는 9%, '4분기(10월)'는 25%의 지급 비율을 \"\n",
      "                                '나타냅니다. 주요 특징으로는 신청 시기에 따른 지급 비율의 차이를 시각적으로 '\n",
      "                                '고찰할 수 있으며, 각각의 시기가 지급에 미치는 영향을 분석할 수 있는 자료임을 '\n",
      "                                '알 수 있습니다.\\n'\n",
      "                                '\\n'\n",
      "                                '\\n'\n",
      "                                '\\n'\n",
      "                                '※ 지급비율은 변동될 수 있으며, 중간평가 결과에 따라 3회차부터 지급을 유예할 '\n",
      "                                '수 있음\\n'\n",
      "                                '\\n'\n",
      "                                '□ 사업비 집행기간\\n'\n",
      "                                '\\n'\n",
      "                                '○ ’24. 1. 1. ~ ’24. 12. 31.\\n'\n",
      "                                '\\n'\n",
      "                                '※ 동 기간 이외의 사용금액은 불인정 금액으로 간주하고 전액 반납해야 함 ※ 단, '\n",
      "                                '집행기간 연장에 대해서 사전 승인을 받을 시에는 그 기한까지는 인정\\n'\n",
      "                                '\\n'\n",
      "                                '2 사업비 계좌관리 및 사용원칙\\n'\n",
      "                                '\\n'\n",
      "                                '□ 사업비 계좌관리\\n'\n",
      "                                '\\n'\n",
      "                                '○ (별도 계좌개설 필수) 각 지원 대상자는 당해 랩 운영지원금과 민간부담금을 '\n",
      "                                '관리하는 통장(법인명의)을 주관·참여기관 별로 각각 개설하고, 해당 계좌와 연계된 '\n",
      "                                '연구비카드(KCA)만 개설하여 사용\\n'\n",
      "                                '\\n'\n",
      "                                '□ 사업비 사용원칙\\n'\n",
      "                                '\\n'\n",
      "                                '○ 총사업비는 당초 제시했던 사업계획에 따른 집행을 원칙으로 함\\n'\n",
      "                                '\\n'\n",
      "                                '○ 원천징수 신고납부 대상인 인건비성 수당의 경우, 소득세 등을 원천징수하고 '\n",
      "                                '나머지 차액을 수령인의 계좌에 송금하여야 하며, 원천징수한 소득세 등은 제작비로 '\n",
      "                                '인정함(원천징수지급조서 작성 첨부)\\n'\n",
      "                                '\\n'\n",
      "                                '- 15 -\\n'\n",
      "                                '\\n'\n",
      "                                '○ 부가가치세, 관세 등 사후 환급이나 공제받을 수 있는 금액은 집행금액에서 '\n",
      "                                '제외함을 원칙으로 하되, 사후 환급이 불가능한 경우에는 예외로 함\\n'\n",
      "                                '\\n'\n",
      "                                '○ 보조금의 적정한 사용을 위하여 프로젝트와 관련 없는 집행과 제한 업종 가맹점 '\n",
      "                                '등에서는 전용 사업비 카드를 사용할 수 없음\\n'\n",
      "                                '\\n'\n",
      "                                '○ 선정 랩의 임직원(직계존비속을 포함) 등이 운영하는 업체 또는 단체 계열 '\n",
      "                                '관계에 있는 업체 또는 단체와는 거래할 수 없음\\n'\n",
      "                                '\\n'\n",
      "                                '※ 컨소시엄 간 계약 불가\\n'\n",
      "                                '\\n'\n",
      "                                '○ 보조금이 투명하고 효율적인 집행을 위하여 수요물자 구매나 시설공사계약을 체결할 '\n",
      "                                '때 아래의 금액에 한하여 조달청(나라장터 등)을 이용해야 함\\n'\n",
      "                                '\\n'\n",
      "                                '- 2천만원을 초과하는 물품 및 용역 구매\\n'\n",
      "                                '\\n'\n",
      "                                '- 2억원을 초과하는 시설공사 계약\\n'\n",
      "                                '\\n'\n",
      "                                '○ 모든 증빙서류는 사업기간 종료 후 5년간 보관해야 하며, 협회가 요구할시 즉시 '\n",
      "                                '응하여야 함\\n'\n",
      "                                '\\n'\n",
      "                                '○ 정부지원금은 콘텐츠 제작 관련 이외의 용도로 사용할 수 없음 < 정부지원금 '\n",
      "                                '사용 불가항목 >\\n'\n",
      "                                '\\n'\n",
      "                                '※ 주관기관, 참여기관 사업비 편성 시 여비는 각 기관별로 산출하여 편성해야 함 '\n",
      "                                '○ 모든 지출은 지출 원인행위 및 지출결과에 대해 증빙할 수 있는 증빙서류가 구비 '\n",
      "                                '되어야 하며, 지출목적이 합당한 경우에만 인정함 ※ [붙임] ICT사업 사업비 '\n",
      "                                '산정 및 정산 등에 관한 기준 및 세부내용 참조\\n'\n",
      "                                '\\n'\n",
      "                                '- 16 -\\n'\n",
      "                                '\\n'\n",
      "                                '3\\n'\n",
      "                                '\\n'\n",
      "                                '인건비 편성\\n'\n",
      "                                '\\n'\n",
      "                                '□ 인건비 편성\\n'\n",
      "                                '\\n'\n",
      "                                '○ 아래 랩 참여인력별 등급 및 월 임금기준에 따라 참여인력 인건비 지원\\n'\n",
      "                                '\\n'\n",
      "                                '- 참여인력 중 대학 및 대학원 교수 직위자들은 인건비 지급을 불인정하고 그 외 '\n",
      "                                '참여인력에 대해서는 100%까지 인정\\n'\n",
      "                                '\\n'\n",
      "                                '예) 1) 교수 직위자\\n'\n",
      "                                '\\n'\n",
      "                                '※ 지원대학(기업) 교수 직위자의 인건비는 불인정\\n'\n",
      "                                '\\n'\n",
      "                                '2) 그 외 참여 인력(박사과정의 경우)\\n'\n",
      "                                '\\n'\n",
      "                                '※ 월 임금 3,000,000원 기준 : 과제 참여율 '\n",
      "                                '50%(1,500,000원)로 편성할 경우, 편성된 참여율의 '\n",
      "                                '100%(1,500,000원)까지 인정\\n'\n",
      "                                '\\n'\n",
      "                                '< 랩 참여인력별 등급 및 월 임금기준* >\\n'\n",
      "                                '\\n'\n",
      "                                '\\n'\n",
      "                                '\\n'\n",
      "                                '[[-- TABLE: Page 3, Index 0 | Path: '\n",
      "                                'manual\\\\tables\\\\p3_tbl0.csv --]]\\n'\n",
      "                                '**표 요약:** 주어진 표는 연구 분야의 인건비 지급 기준과 자격 기준에 대한 '\n",
      "                                '정보를 담고 있습니다. 이 표는 네 가지 등급(박사후연구원, 박사과정, 석사과정, '\n",
      "                                '학사과정)으로 구분되어 있으며, 각 등급별로 월 임금과 자격 기준이 명시되어 '\n",
      "                                '있습니다.\\n'\n",
      "                                '\\n'\n",
      "                                '주요 특징은 다음과 같습니다:\\n'\n",
      "                                '1. 박사후연구원은 소속 기관의 인건비 지급 기준에 따라 지급되며, 박사급 전문 '\n",
      "                                '지식을 보유한 자로서 연구 분야에서 실무 역할을 수행합니다.\\n'\n",
      "                                '2. 박사과정과 석사과정은 각각 최소 월 3,000,000원과 '\n",
      "                                '2,200,000원의 임금을 받으며, 해당 수준의 전문 지식을 보유한 대학원 '\n",
      "                                '과정인자로 제한됩니다.\\n'\n",
      "                                '3. 학사과정은 최소 월 1,300,000원을 기준으로 하며, 주로 콘텐츠 사업 '\n",
      "                                '및 R&D 관련 업무를 수행하는 학사 과정인자를 대상으로 합니다. \\n'\n",
      "                                '\\n'\n",
      "                                '이 표는 연구 및 콘텐츠 산업에 종사하는 인력의 직급에 따른 보상 체계와 요구되는 '\n",
      "                                '자격을 명확하게 제시하고 있습니다.\\n'\n",
      "                                '\\n'\n",
      "                                '\\n'\n",
      "                                '\\n'\n",
      "                                '콘텐츠 사업, R&D 등 역할을 수행하는 실무자로,\\n'\n",
      "                                '\\n'\n",
      "                                '당해 연구분야에 대해 박사급 전문지식을 보유한 자,\\n'\n",
      "                                '\\n'\n",
      "                                '콘텐츠 사업, R&D 등 역할을 수행하는 실무자로,\\n'\n",
      "                                '\\n'\n",
      "                                '당해 연구분야에 대해 박사급 전문지식을 보유한 자,\\n'\n",
      "                                '\\n'\n",
      "                                '콘텐츠 사업, R&D 등 역할을 수행하는 실무자로,\\n'\n",
      "                                '\\n'\n",
      "                                '당해 연구분야에 대해 석사급 전문지식을 보유한 자,\\n'\n",
      "                                '\\n'\n",
      "                                '콘텐츠 사업 및 R&D 수행하는 자로써 학사과정인자,\\n'\n",
      "                                '\\n'\n",
      "                                '※ 통합과정의 경우 학사, 석사, 박사과정의 기준을 고려하여 소속기관의 장이 '\n",
      "                                '별도로 정한 금액으로 월 임금 기준 편성\\n'\n",
      "                                '\\n'\n",
      "                                '※ 본 인건비 기준단가는 참여율 100%로 산정한 것이며, 참여율을 달리하는 경우 '\n",
      "                                '증감하여 적용\\n'\n",
      "                                '\\n'\n",
      "                                '* 국가연구개발사업 연구개발비 사용기준 제 40조(정부출연기관 학생인건비 '\n",
      "                                '사용기준) 준용\\n'\n",
      "                                '\\n'\n",
      "                                '- 17 -',\n",
      " 'integrated_markdown_file': 'manual\\\\integrated_markdown_camelot.md',\n",
      " 'output_dir': 'manual',\n",
      " 'tables': [{'dataframe':            0       1                    2       3                     4  \\\n",
      "0      1~2분기                                                      3~4분기   \n",
      "1        1회차                          2회차                           3회차   \n",
      "2     신청\\n시기  지급\\n비율               신청\\n시기  지급\\n비율                신청\\n시기   \n",
      "3  협약\\n체결  시     20%  협약\\n체결  후\\n2개월 \\n이내     46%  중간\\n평가  후 \\n1개월 \\n이내   \n",
      "\n",
      "        5           6       7  \n",
      "0                              \n",
      "1                 4회차          \n",
      "2  지급\\n비율      신청\\n시기  지급\\n비율  \n",
      "3      9%  4분기\\n(10월)     25%  ,\n",
      "             'description': '이 표는 특정 기간에 따른 신청 시기와 지급 비율에 대한 정보를 담고 있습니다. 각 '\n",
      "                            \"분기별로 지급 비율이 다르게 나타나며, '협약 체결 시'에는 20%, '협약 체결 후 \"\n",
      "                            \"2개월 이내'에서는 46%의 지급 비율이 있는 반면, '중간 평가 후 1개월 이내'는 \"\n",
      "                            \"9%, '4분기(10월)'는 25%의 지급 비율을 나타냅니다. 주요 특징으로는 신청 \"\n",
      "                            '시기에 따른 지급 비율의 차이를 시각적으로 고찰할 수 있으며, 각각의 시기가 지급에 '\n",
      "                            '미치는 영향을 분석할 수 있는 자료임을 알 수 있습니다.',\n",
      "             'page': 1,\n",
      "             'path': 'manual\\\\tables\\\\p1_tbl0.csv'},\n",
      "            {'dataframe':         0                     1  \\\n",
      "0    등  급  월  임금\\n(100%참여율  기준)   \n",
      "1  박사후연구원      소속기관 \\n인건비  지급기준   \n",
      "2    박사과정      월  3,000,000원 이상   \n",
      "3    석사과정       월 2,200,000원 이상   \n",
      "4    학사과정       월 1,300,000원 이상   \n",
      "\n",
      "                                                   2  \n",
      "0                                         자  격  기  준  \n",
      "1  콘텐츠  사업,  R&D  등  역할을  수행하는  실무자로, \\n당해  연구분야에...  \n",
      "2  콘텐츠  사업,  R&D  등  역할을  수행하는  실무자로, \\n당해  연구분야에...  \n",
      "3  콘텐츠  사업,  R&D  등  역할을  수행하는  실무자로, \\n당해  연구분야에...  \n",
      "4  콘텐츠  사업  및  R&D  수행하는  자로써  학사과정인자, \\n회계,  정산,...  ,\n",
      "             'description': '주어진 표는 연구 분야의 인건비 지급 기준과 자격 기준에 대한 정보를 담고 있습니다. 이 '\n",
      "                            '표는 네 가지 등급(박사후연구원, 박사과정, 석사과정, 학사과정)으로 구분되어 있으며, '\n",
      "                            '각 등급별로 월 임금과 자격 기준이 명시되어 있습니다.\\n'\n",
      "                            '\\n'\n",
      "                            '주요 특징은 다음과 같습니다:\\n'\n",
      "                            '1. 박사후연구원은 소속 기관의 인건비 지급 기준에 따라 지급되며, 박사급 전문 지식을 '\n",
      "                            '보유한 자로서 연구 분야에서 실무 역할을 수행합니다.\\n'\n",
      "                            '2. 박사과정과 석사과정은 각각 최소 월 3,000,000원과 2,200,000원의 '\n",
      "                            '임금을 받으며, 해당 수준의 전문 지식을 보유한 대학원 과정인자로 제한됩니다.\\n'\n",
      "                            '3. 학사과정은 최소 월 1,300,000원을 기준으로 하며, 주로 콘텐츠 사업 및 '\n",
      "                            'R&D 관련 업무를 수행하는 학사 과정인자를 대상으로 합니다. \\n'\n",
      "                            '\\n'\n",
      "                            '이 표는 연구 및 콘텐츠 산업에 종사하는 인력의 직급에 따른 보상 체계와 요구되는 자격을 '\n",
      "                            '명확하게 제시하고 있습니다.',\n",
      "             'page': 3,\n",
      "             'path': 'manual\\\\tables\\\\p3_tbl0.csv'}]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654289a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 생성된 Document 객체 (상위 2개) ---\n",
      "--- Chunk 1 ---\n",
      "Page Content:\n",
      "Ⅴ 사업비 집행 및 정산지침\n",
      "\n",
      "OE...\n",
      "\n",
      "Metadata:\n",
      "{'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Page Content:\n",
      "사업비 지급 및 집행기간...\n",
      "\n",
      "Metadata:\n",
      "{'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}\n",
      "\n",
      "\n",
      "--- Vector Store 생성 시작 ---\n",
      "임베딩 모델을 위한 디바이스 설정: cuda\n",
      "\n",
      "--- Vector Store 생성 및 저장 완료 ---\n",
      "'./chroma_db' 디렉토리에 38개의 청크가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document  # Document 클래스를 import 합니다.\n",
    "\n",
    "# --- 1. 메타데이터를 포함하여 청킹하고 Document 객체를 생성하는 함수 ---\n",
    "\n",
    "def create_documents_from_markdown(markdown_content, source_path):\n",
    "    \"\"\"\n",
    "    논리적 청킹을 수행하고, 각 청크를 메타데이터가 포함된 LangChain Document 객체로 변환합니다.\n",
    "\n",
    "    Args:\n",
    "        markdown_content (str): 청킹할 마크다운 전체 텍스트\n",
    "        source_path (str): 원본 파일 경로 (메타데이터에 사용)\n",
    "\n",
    "    Returns:\n",
    "        list[Document]: 내용과 메타데이터가 포함된 Document 객체 리스트\n",
    "    \"\"\"\n",
    "    # 기존의 논리적 청킹 함수를 그대로 사용합니다.\n",
    "    text_chunks = chunk_markdown_logically(markdown_content)\n",
    "    \n",
    "    documents = []\n",
    "    for chunk_text in text_chunks:\n",
    "        metadata = {\"source\": source_path}  # 모든 청크에 기본 출처 정보 추가\n",
    "        \n",
    "        # 청크 내용을 기반으로 추가 메타데이터 파싱\n",
    "        if chunk_text.startswith(\"[[-- TABLE:\"):\n",
    "            metadata['type'] = 'table'\n",
    "            # 정규표현식을 사용하여 페이지 번호와 경로 추출\n",
    "            page_match = re.search(r\"Page (\\d+)\", chunk_text)\n",
    "            path_match = re.search(r\"Path: (.*?)\\s*--]]\", chunk_text)\n",
    "            if page_match:\n",
    "                metadata['page'] = int(page_match.group(1))\n",
    "            if path_match:\n",
    "                metadata['table_path'] = path_match.group(1).strip()\n",
    "\n",
    "        elif chunk_text.startswith(\"![\"):\n",
    "            metadata['type'] = 'image'\n",
    "            # 정규표현식을 사용하여 페이지 번호와 이미지 설명 추출\n",
    "            page_match = re.search(r\"Image from page (\\d+)\", chunk_text)\n",
    "            desc_match = re.search(r\"!\\[(.*?)\\]\\(\", chunk_text)\n",
    "            if page_match:\n",
    "                metadata['page'] = int(page_match.group(1))\n",
    "            if desc_match:\n",
    "                metadata['description'] = desc_match.group(1).strip()\n",
    "        else:\n",
    "            metadata['type'] = 'text'\n",
    "\n",
    "        # Document 객체 생성\n",
    "        doc = Document(page_content=chunk_text, metadata=metadata)\n",
    "        documents.append(doc)\n",
    "        \n",
    "    return documents\n",
    "\n",
    "# --- 2. 기존 로직 실행 및 all_chunks 생성 ---\n",
    "\n",
    "# chunk_markdown_logically 함수는 제공된 코드에 이미 정의되어 있다고 가정합니다.\n",
    "def chunk_markdown_logically(markdown_content):\n",
    "    \"\"\"\n",
    "    문서의 구조(제목, 표, 이미지)를 이해하여 논리적인 단위로 청킹합니다.\n",
    "    RAG 시스템에 가장 효과적인 방법입니다.\n",
    "    \"\"\"\n",
    "    # 1. 기본 블록으로 분리\n",
    "    blocks = markdown_content.split('\\n\\n')\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for block in blocks:\n",
    "        block = block.strip()\n",
    "        if not block:\n",
    "            continue\n",
    "\n",
    "        # 2. 규칙에 따라 청크 생성\n",
    "        is_table_placeholder = block.startswith(\"[[-- TABLE:\")\n",
    "        is_image_link = block.startswith(\"![\")\n",
    "        # 제목으로 사용될 수 있는 패턴들 (필요에 따라 추가)\n",
    "        is_heading = block.startswith(('□', '○', '※')) or re.match(r'^[0-9]+\\s|^\\w+\\s', block) and len(block) < 50\n",
    "\n",
    "        if is_table_placeholder or is_image_link:\n",
    "            # 테이블/이미지는 독립적인 청크로 처리\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            chunks.append(block)\n",
    "            current_chunk = \"\"\n",
    "        elif is_heading:\n",
    "            # 제목은 다음 블록과 합치기 위해, 진행 중인 청크를 먼저 저장\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = block\n",
    "        else:\n",
    "            # 일반 텍스트는 현재 청크(제목 또는 이전 텍스트)에 추가\n",
    "            if current_chunk:\n",
    "                current_chunk += \"\\n\\n\" + block\n",
    "            else:\n",
    "                current_chunk = block\n",
    "    \n",
    "    # 마지막 남은 청크 추가\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "        \n",
    "    return chunks\n",
    "\n",
    "source_file_path = \"manual/integrated_markdown_camelot.md\"\n",
    "\n",
    "with open(source_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# 'all_chunks' 변수는 이제 단순 문자열 리스트가 아닌,\n",
    "# 내용과 메타데이터를 모두 포함한 Document 객체의 리스트가 됩니다.\n",
    "all_chunks = create_documents_from_markdown(content, source_file_path)\n",
    "\n",
    "\n",
    "# --- 생성된 Document 객체 확인 (상위 2개) ---\n",
    "print(\"--- 생성된 Document 객체 (상위 2개) ---\")\n",
    "for i, doc in enumerate(all_chunks[:2]):\n",
    "    print(f\"--- Chunk {i+1} ---\")\n",
    "    print(f\"Page Content:\\n{doc.page_content[:200]}...\\n\") # 내용이 길 수 있으므로 일부만 출력\n",
    "    print(f\"Metadata:\\n{doc.metadata}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17e88c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "source_file_path = \"manual/integrated_markdown_camelot.md\"\n",
    "\n",
    "with open(source_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, # 청크 크기를 1000으로 설정\n",
    "    chunk_overlap=150,  # 중첩 크기를 150으로 설정\n",
    "    length_function=len, # 텍스트 길이를 계산할 함수 지정\n",
    ")\n",
    "\n",
    "# .split_text() 메서드를 사용하여 텍스트를 분할합니다.\n",
    "split_texts = text_splitter.split_text(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26501f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Vector Store 생성 시작 ---\n",
      "임베딩 모델을 위한 디바이스 설정: cuda\n",
      "\n",
      "--- Vector Store 생성 및 저장 완료 ---\n",
      "'./chroma_db' 디렉토리에 38개의 청크가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Vector Store 생성 및 저장 ---\n",
    "\n",
    "print(\"\\n--- Vector Store 생성 시작 ---\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"임베딩 모델을 위한 디바이스 설정: {device}\")\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"dragonkue/BGE-m3-ko\",\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'normalize_embeddings': True},\n",
    ")\n",
    "\n",
    "# Chroma.from_documents 함수는 Document 객체 리스트를 받도록 설계되어 있습니다.\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_db\"  # DB를 저장할 디렉토리\n",
    ")\n",
    "\n",
    "print(\"\\n--- Vector Store 생성 및 저장 완료 ---\")\n",
    "print(f\"'{vectorstore._persist_directory}' 디렉토리에 {len(all_chunks)}개의 청크가 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d42303eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='Ⅴ 사업비 집행 및 정산지침\\n\\nOE'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='사업비 지급 및 집행기간'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='□ 사업비 지급'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'table', 'page': 1, 'table_path': 'manual\\\\tables\\\\p1_tbl0.csv'}, page_content=\"[[-- TABLE: Page 1, Index 0 | Path: manual\\\\tables\\\\p1_tbl0.csv --]]\\n**표 요약:** 이 표는 특정 기간에 따른 신청 시기와 지급 비율에 대한 정보를 담고 있습니다. 각 분기별로 지급 비율이 다르게 나타나며, '협약 체결 시'에는 20%, '협약 체결 후 2개월 이내'에서는 46%의 지급 비율이 있는 반면, '중간 평가 후 1개월 이내'는 9%, '4분기(10월)'는 25%의 지급 비율을 나타냅니다. 주요 특징으로는 신청 시기에 따른 지급 비율의 차이를 시각적으로 고찰할 수 있으며, 각각의 시기가 지급에 미치는 영향을 분석할 수 있는 자료임을 알 수 있습니다.\"),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='※ 지급비율은 변동될 수 있으며, 중간평가 결과에 따라 3회차부터 지급을 유예할 수 있음'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='□ 사업비 집행기간'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='○ ’24. 1. 1. ~ ’24. 12. 31.'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='※ 동 기간 이외의 사용금액은 불인정 금액으로 간주하고 전액 반납해야 함 ※ 단, 집행기간 연장에 대해서 사전 승인을 받을 시에는 그 기한까지는 인정'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='2 사업비 계좌관리 및 사용원칙'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='□ 사업비 계좌관리'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='○ (별도 계좌개설 필수) 각 지원 대상자는 당해 랩 운영지원금과 민간부담금을 관리하는 통장(법인명의)을 주관·참여기관 별로 각각 개설하고, 해당 계좌와 연계된 연구비카드(KCA)만 개설하여 사용'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='□ 사업비 사용원칙'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='○ 총사업비는 당초 제시했던 사업계획에 따른 집행을 원칙으로 함'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='○ 원천징수 신고납부 대상인 인건비성 수당의 경우, 소득세 등을 원천징수하고 나머지 차액을 수령인의 계좌에 송금하여야 하며, 원천징수한 소득세 등은 제작비로 인정함(원천징수지급조서 작성 첨부)\\n\\n- 15 -'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='○ 부가가치세, 관세 등 사후 환급이나 공제받을 수 있는 금액은 집행금액에서 제외함을 원칙으로 하되, 사후 환급이 불가능한 경우에는 예외로 함'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='○ 보조금의 적정한 사용을 위하여 프로젝트와 관련 없는 집행과 제한 업종 가맹점 등에서는 전용 사업비 카드를 사용할 수 없음'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='○ 선정 랩의 임직원(직계존비속을 포함) 등이 운영하는 업체 또는 단체 계열 관계에 있는 업체 또는 단체와는 거래할 수 없음'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='※ 컨소시엄 간 계약 불가'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='○ 보조금이 투명하고 효율적인 집행을 위하여 수요물자 구매나 시설공사계약을 체결할 때 아래의 금액에 한하여 조달청(나라장터 등)을 이용해야 함\\n\\n- 2천만원을 초과하는 물품 및 용역 구매\\n\\n- 2억원을 초과하는 시설공사 계약'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='○ 모든 증빙서류는 사업기간 종료 후 5년간 보관해야 하며, 협회가 요구할시 즉시 응하여야 함'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='○ 정부지원금은 콘텐츠 제작 관련 이외의 용도로 사용할 수 없음 < 정부지원금 사용 불가항목 >'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='※ 주관기관, 참여기관 사업비 편성 시 여비는 각 기관별로 산출하여 편성해야 함 ○ 모든 지출은 지출 원인행위 및 지출결과에 대해 증빙할 수 있는 증빙서류가 구비 되어야 하며, 지출목적이 합당한 경우에만 인정함 ※ [붙임] ICT사업 사업비 산정 및 정산 등에 관한 기준 및 세부내용 참조\\n\\n- 16 -\\n\\n3'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='인건비 편성'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='□ 인건비 편성'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='○ 아래 랩 참여인력별 등급 및 월 임금기준에 따라 참여인력 인건비 지원\\n\\n- 참여인력 중 대학 및 대학원 교수 직위자들은 인건비 지급을 불인정하고 그 외 참여인력에 대해서는 100%까지 인정\\n\\n예) 1) 교수 직위자'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='※ 지원대학(기업) 교수 직위자의 인건비는 불인정\\n\\n2) 그 외 참여 인력(박사과정의 경우)'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='※ 월 임금 3,000,000원 기준 : 과제 참여율 50%(1,500,000원)로 편성할 경우, 편성된 참여율의 100%(1,500,000원)까지 인정\\n\\n< 랩 참여인력별 등급 및 월 임금기준* >'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'table', 'page': 3, 'table_path': 'manual\\\\tables\\\\p3_tbl0.csv'}, page_content='[[-- TABLE: Page 3, Index 0 | Path: manual\\\\tables\\\\p3_tbl0.csv --]]\\n**표 요약:** 주어진 표는 연구 분야의 인건비 지급 기준과 자격 기준에 대한 정보를 담고 있습니다. 이 표는 네 가지 등급(박사후연구원, 박사과정, 석사과정, 학사과정)으로 구분되어 있으며, 각 등급별로 월 임금과 자격 기준이 명시되어 있습니다.'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='주요 특징은 다음과 같습니다:\\n1. 박사후연구원은 소속 기관의 인건비 지급 기준에 따라 지급되며, 박사급 전문 지식을 보유한 자로서 연구 분야에서 실무 역할을 수행합니다.\\n2. 박사과정과 석사과정은 각각 최소 월 3,000,000원과 2,200,000원의 임금을 받으며, 해당 수준의 전문 지식을 보유한 대학원 과정인자로 제한됩니다.\\n3. 학사과정은 최소 월 1,300,000원을 기준으로 하며, 주로 콘텐츠 사업 및 R&D 관련 업무를 수행하는 학사 과정인자를 대상으로 합니다.\\n\\n이 표는 연구 및 콘텐츠 산업에 종사하는 인력의 직급에 따른 보상 체계와 요구되는 자격을 명확하게 제시하고 있습니다.'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='콘텐츠 사업, R&D 등 역할을 수행하는 실무자로,'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='당해 연구분야에 대해 박사급 전문지식을 보유한 자,'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='콘텐츠 사업, R&D 등 역할을 수행하는 실무자로,'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='당해 연구분야에 대해 박사급 전문지식을 보유한 자,'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='콘텐츠 사업, R&D 등 역할을 수행하는 실무자로,'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='당해 연구분야에 대해 석사급 전문지식을 보유한 자,'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='콘텐츠 사업 및 R&D 수행하는 자로써 학사과정인자,'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='※ 통합과정의 경우 학사, 석사, 박사과정의 기준을 고려하여 소속기관의 장이 별도로 정한 금액으로 월 임금 기준 편성'),\n",
      " Document(metadata={'source': 'manual/integrated_markdown_camelot.md', 'type': 'text'}, page_content='※ 본 인건비 기준단가는 참여율 100%로 산정한 것이며, 참여율을 달리하는 경우 증감하여 적용\\n\\n* 국가연구개발사업 연구개발비 사용기준 제 40조(정부출연기관 학생인건비 사용기준) 준용\\n\\n- 17 -')]\n"
     ]
    }
   ],
   "source": [
    "pprint(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c968cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If the user asks for a simple answer, summarize the key points.\n",
    "If the question is unrelated to the context in the regulations, respond with \"관련 정보를 찾을 수 없습니다.\"\n",
    "Answer in Korean.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "llm = OllamaLLM(model=\"gemma3:4b\")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "25eb37da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "관련 정보를 찾을 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "question = \"2회차 사업비 지급 비율은?\"\n",
    "answer = chain.invoke(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d123918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "import os\n",
    "import pandas as pd\n",
    "import markdownify\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def extract_pdf_elements(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트, 이미지, 표를 추출하여 별도로 저장하는 함수\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): 처리할 PDF 파일의 경로\n",
    "\n",
    "    Returns:\n",
    "        dict: 추출된 텍스트, 이미지 정보, 표 정보가 담긴 딕셔너리\n",
    "    \"\"\"\n",
    "    \n",
    "    output_dir = os.path.basename(pdf_path).split(\".\")[0]\n",
    "    image_dir = os.path.join(output_dir, \"images\")\n",
    "    table_dir = os.path.join(output_dir, \"tables\")\n",
    "    \n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "    os.makedirs(table_dir, exist_ok=True)\n",
    "    \n",
    "    all_text = []\n",
    "    image_info = []\n",
    "    table_info = []\n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as plumber_pdf:\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            plumber_page = plumber_pdf.pages[page_num]\n",
    "            \n",
    "            # 텍스트 추출\n",
    "            all_text.append(page.get_text(\"html\"))\n",
    "            \n",
    "            \n",
    "            # 이미지 추출\n",
    "            images = page.get_images(full=True)\n",
    "            for img_index, img in enumerate(images):\n",
    "                xref = img[0]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                image_ext = base_image[\"ext\"]\n",
    "                \n",
    "                image_filename = f\"p{page_num + 1}_img{img_index}.{image_ext}\"\n",
    "                image_path = os.path.join(image_dir, image_filename)\n",
    "                \n",
    "                with open(image_path, \"wb\") as img_file:\n",
    "                    img_file.write(image_bytes)\n",
    "                    \n",
    "                    image_info.append({\n",
    "                        \"path\":image_path,\n",
    "                        \"page\":page_num+1,\n",
    "                        \"description\":\"\"\n",
    "                    })\n",
    "                    \n",
    "            # 테이블 추출\n",
    "            tables = plumber_page.extract_tables()\n",
    "            for table_index, table in enumerate(tables):\n",
    "                df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                \n",
    "                table_filename = f\"p{page_num + 1}_tbl{table_index}.csv\"\n",
    "                table_path = os.path.join(table_dir, table_filename)\n",
    "                \n",
    "                df.to_csv(table_path, index=False, encoding=\"utf-8-sig\")\n",
    "                \n",
    "                table_info.append({\n",
    "                    \"path\":table_path,\n",
    "                    \"page\":page_num+1,\n",
    "                    \"description\":\"\",\n",
    "                    \"dataframe\":df\n",
    "                })\n",
    "                \n",
    "    doc.close()\n",
    "    \n",
    "    full_text = \"\\n\".join(all_text)\n",
    "    full_markdown = markdownify.markdownify(full_text, heading_style=\"ATX\")\n",
    "    \n",
    "    text_filename = os.path.join(output_dir, \"full_markdown.txt\")\n",
    "    with open(text_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(full_markdown)\n",
    "        \n",
    "    return {\n",
    "        \"output_dir\":output_dir,\n",
    "        \"text_file\":text_filename,\n",
    "        \"images\":image_info,\n",
    "        \"tables\":table_info,\n",
    "        \"text_per_page\": full_markdown\n",
    "    }\n",
    "    \n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "def generate_image_description(image_path):\n",
    "    base64_image = encode_image_to_base64(image_path)\n",
    "    image_ext = os.path.splitext(image_path)[1].lstrip('.')\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"이 이미지는 무엇에 관한 것인가요? RAG 시스템에서 검색될 것을 가정하고, 이미지의 핵심 내용을 간결하게 한글로 설명해주세요.\"},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/{image_ext};base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=200\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def generate_table_summary(table_csv_str):\n",
    "    if len(table_csv_str) > 4000:\n",
    "        table_csv_str = table_csv_str[:4000]\n",
    "        \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"당신은 데이터 분석가입니다. 주어진 표 데이터를 보고, 표의 핵심 내용을 간결하게 한글 문장으로 요약하는 역할을 맡았습니다.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"다음은 표 데이터입니다. 이 표가 어떤 정보를 담고 있으며, 주요 특징이 무엇인지 한두 문장으로 요약해주세요.\\n\\n--- 데이터 시작 ---\\n{table_csv_str}\\n--- 데이터 끝 ---\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc67c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "죄송합니다. 이 이미지는 회색 배경이라서 구체적인 내용을 알 수 없습니다. \n",
      "이 표는 여비 산정에 대한 기준을 담고 있으며, 출장 및 여행 시 필요한 비용 산정의 근거와 기준을 명확히 제시하는 정보를 포함하고 있습니다.\n",
      "주어진 데이터는 '여비산정기준표'라는 제목을 가진 표로, 여비 산정을 위한 기준이나 규정을 담고 있는 것으로 보입니다. 구체적인 항목이나 내용은 주어지지 않았지만, 여행 경비나 출장을 위한 비용 산정에 관련된 정보를 제공하는 것 같습니다.\n",
      "표 데이터는 여행 경비를 산정하는 기준을 담고 있는 것으로 보입니다. 주요 특징은 출장이나 여행 시 필요한 경비를 효율적으로 계산할 수 있도록 가이드라인을 제공하는 것입니다.\n",
      "제공된 표는 여비 산정을 위한 기준을 담고 있으며, 출장 시 교통비, 숙박비 등의 경비를 산정하는 표준을 제시하고 있습니다. 주요 특징은 각 항목별로 세부 산정 기준이 명시되어 있다는 점입니다.\n",
      "표 데이터는 여비 산정에 관한 기준을 제시하고 있는 것으로 보입니다. 주로 출장 등에 필요한 여비를 계산하는 데 필요한 기준과 요율이 포함되어 있을 가능성이 높습니다.\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"datasets/여비산정기준표.pdf\"\n",
    "extracted_data = extract_pdf_elements(pdf_path)\n",
    "\n",
    "for i, image_item in enumerate(extracted_data[\"images\"]):\n",
    "    description = generate_image_description(image_item['path'])\n",
    "    image_item[\"description\"] = description\n",
    "    print(description)\n",
    "    \n",
    "for i, table_item in enumerate(extracted_data[\"tables\"]):\n",
    "    description = generate_table_summary(table_item['path'])\n",
    "    table_item[\"description\"] = description\n",
    "    print(description)\n",
    "    \n",
    "\n",
    "output_dir = extracted_data['output_dir']\n",
    "json_data_path = os.path.join(output_dir, 'enriched_data.json')\n",
    "# DataFrame 객체는 JSON으로 바로 저장되지 않으므로 제외\n",
    "for tbl in extracted_data['tables']:\n",
    "    del tbl['dataframe']\n",
    "    \n",
    "with open(json_data_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(extracted_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_map = {\n",
    "    i + 1: [page_text] for i, page_text in enumerate(extracted_data[\"text_per_page\"])\n",
    "}\n",
    "\n",
    "with open(json_data_path, 'r', encoding='utf-8') as f:\n",
    "    enriched_data = json.load(f)\n",
    "    \n",
    "for image in enriched_data[\"images\"]:\n",
    "    page_num = image[\"page\"]\n",
    "    description = image[\"description\"]\n",
    "    \n",
    "    formatted_desc = f\"\\n[이미지 파일: {os.path.basename(image['path'])}]\\n이미지 설명: {description}\\n\"\n",
    "    if page_num in content_map:\n",
    "        content_map[page_num].append(formatted_desc)\n",
    "        \n",
    "for table in enriched_data[\"tables\"]:\n",
    "    page_num = table[\"page\"]\n",
    "    summary = table[\"description\"]\n",
    "    \n",
    "    formatted_summary = f\"\\n[표 파일: {os.path.basename(table['path'])}]\\n표 요약: {summary}\\n\"\n",
    "    if page_num in content_map:\n",
    "        content_map[page_num].append(formatted_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962569a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pages_content = []\n",
    "for page_num in sorted(content_map.keys()):\n",
    "    page_content = '\\n'.join(content_map[page_num])\n",
    "    final_pages_content.append(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6d44cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 마크다운에 적합한 스플리터\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=100,\n",
    "    # 마크다운 구조를 우선적으로 고려하여 분리\n",
    "    separators=[\"\\n## \", \"\\n### \", \"\\n#### \", \"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "all_chunks = []\n",
    "for i, page_text in enumerate(final_pages_content):\n",
    "    page_num = i+1\n",
    "    chunks = text_splitter.create_documents(\n",
    "        texts=[page_text],\n",
    "        metadatas=[{\"source_page\":page_num}]\n",
    "    )\n",
    "    all_chunks.extend(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123fedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 생성된 Document 객체 (상위 2개) ---\n",
      "--- Chunk 1 ---\n",
      "Page Content:\n",
      "Ⅴ 사업비 집행 및 정산지침\n",
      "\n",
      "rau...\n",
      "\n",
      "Metadata:\n",
      "{'source': 'manual/integrated_markdown_plumber.md', 'type': 'text'}\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Page Content:\n",
      "사업비 지급 및 집행기간...\n",
      "\n",
      "Metadata:\n",
      "{'source': 'manual/integrated_markdown_plumber.md', 'type': 'text'}\n",
      "\n",
      "\n",
      "--- Vector Store 생성 시작 ---\n",
      "임베딩 모델을 위한 디바이스 설정: mps\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/rag/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:83\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 91\u001b[0m\n\u001b[1;32m     84\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(\n\u001b[1;32m     85\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdragonkue/BGE-m3-ko\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     86\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: device},\n\u001b[1;32m     87\u001b[0m     encode_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalize_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[1;32m     88\u001b[0m )\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Chroma.from_documents 함수는 Document 객체 리스트를 받도록 설계되어 있습니다.\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./chroma_db\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# DB를 저장할 디렉토리\u001b[39;49;00m\n\u001b[1;32m     95\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Vector Store 생성 및 저장 완료 ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvectorstore\u001b[38;5;241m.\u001b[39m_persist_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 디렉토리에 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m개의 청크가 저장되었습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rag/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:887\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    886\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 887\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rag/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:817\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chroma:\n\u001b[1;32m    798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \n\u001b[1;32m    800\u001b[0m \u001b[38;5;124;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;124;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 817\u001b[0m     chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m         ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rag/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:224\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     emit_warning()\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rag/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:86\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import chromadb python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install chromadb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_settings \u001b[38;5;241m=\u001b[39m client_settings\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import chromadb python package. Please install it with `pip install chromadb`."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document  # Document 클래스를 import 합니다.\n",
    "\n",
    "# --- 1. 메타데이터를 포함하여 청킹하고 Document 객체를 생성하는 함수 ---\n",
    "\n",
    "def create_documents_from_markdown(markdown_content, source_path):\n",
    "    \"\"\"\n",
    "    논리적 청킹을 수행하고, 각 청크를 메타데이터가 포함된 LangChain Document 객체로 변환합니다.\n",
    "\n",
    "    Args:\n",
    "        markdown_content (str): 청킹할 마크다운 전체 텍스트\n",
    "        source_path (str): 원본 파일 경로 (메타데이터에 사용)\n",
    "\n",
    "    Returns:\n",
    "        list[Document]: 내용과 메타데이터가 포함된 Document 객체 리스트\n",
    "    \"\"\"\n",
    "    # 기존의 논리적 청킹 함수를 그대로 사용합니다.\n",
    "    text_chunks = chunk_markdown_logically(markdown_content)\n",
    "    \n",
    "    documents = []\n",
    "    for chunk_text in text_chunks:\n",
    "        metadata = {\"source\": source_path}  # 모든 청크에 기본 출처 정보 추가\n",
    "        \n",
    "        # 청크 내용을 기반으로 추가 메타데이터 파싱\n",
    "        if chunk_text.startswith(\"[[-- TABLE:\"):\n",
    "            metadata['type'] = 'table'\n",
    "            # 정규표현식을 사용하여 페이지 번호와 경로 추출\n",
    "            page_match = re.search(r\"Page (\\d+)\", chunk_text)\n",
    "            path_match = re.search(r\"Path: (.*?)\\s*--]]\", chunk_text)\n",
    "            if page_match:\n",
    "                metadata['page'] = int(page_match.group(1))\n",
    "            if path_match:\n",
    "                metadata['table_path'] = path_match.group(1).strip()\n",
    "\n",
    "        elif chunk_text.startswith(\"![\"):\n",
    "            metadata['type'] = 'image'\n",
    "            # 정규표현식을 사용하여 페이지 번호와 이미지 설명 추출\n",
    "            page_match = re.search(r\"Image from page (\\d+)\", chunk_text)\n",
    "            desc_match = re.search(r\"!\\[(.*?)\\]\\(\", chunk_text)\n",
    "            if page_match:\n",
    "                metadata['page'] = int(page_match.group(1))\n",
    "            if desc_match:\n",
    "                metadata['description'] = desc_match.group(1).strip()\n",
    "        else:\n",
    "            metadata['type'] = 'text'\n",
    "\n",
    "        # Document 객체 생성\n",
    "        doc = Document(page_content=chunk_text, metadata=metadata)\n",
    "        documents.append(doc)\n",
    "        \n",
    "    return documents\n",
    "\n",
    "# --- 2. 기존 로직 실행 및 all_chunks 생성 ---\n",
    "\n",
    "# chunk_markdown_logically 함수는 제공된 코드에 이미 정의되어 있다고 가정합니다.\n",
    "# def chunk_markdown_logically(markdown_content): ...\n",
    "\n",
    "source_file_path = \"manual/integrated_markdown_plumber.md\"\n",
    "\n",
    "with open(source_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# 'all_chunks' 변수는 이제 단순 문자열 리스트가 아닌,\n",
    "# 내용과 메타데이터를 모두 포함한 Document 객체의 리스트가 됩니다.\n",
    "all_chunks = create_documents_from_markdown(content, source_file_path)\n",
    "\n",
    "\n",
    "# --- 생성된 Document 객체 확인 (상위 2개) ---\n",
    "print(\"--- 생성된 Document 객체 (상위 2개) ---\")\n",
    "for i, doc in enumerate(all_chunks[:2]):\n",
    "    print(f\"--- Chunk {i+1} ---\")\n",
    "    print(f\"Page Content:\\n{doc.page_content[:200]}...\\n\") # 내용이 길 수 있으므로 일부만 출력\n",
    "    print(f\"Metadata:\\n{doc.metadata}\\n\")\n",
    "\n",
    "\n",
    "# --- 3. Vector Store 생성 및 저장 ---\n",
    "\n",
    "print(\"\\n--- Vector Store 생성 시작 ---\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"임베딩 모델을 위한 디바이스 설정: {device}\")\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"dragonkue/BGE-m3-ko\",\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'normalize_embeddings': True},\n",
    ")\n",
    "\n",
    "# Chroma.from_documents 함수는 Document 객체 리스트를 받도록 설계되어 있습니다.\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_db\"  # DB를 저장할 디렉토리\n",
    ")\n",
    "\n",
    "print(\"\\n--- Vector Store 생성 및 저장 완료 ---\")\n",
    "print(f\"'{vectorstore._persist_directory}' 디렉토리에 {len(all_chunks)}개의 청크가 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700de623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf6bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3769b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 22:03:20.273 python[64743:7789898] The class 'NSOpenPanel' overrides the method identifier.  This method is implemented by class 'NSWindow'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/rag/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import requests\n",
    "from PyQt6.QtWidgets import (\n",
    "    QApplication, QWidget, QVBoxLayout, QHBoxLayout, QPushButton, QLabel, \n",
    "    QFileDialog, QLineEdit, QTextEdit, QFrame\n",
    ")\n",
    "from PyQt6.QtCore import Qt\n",
    "\n",
    "class DragDropLabel(QLabel):\n",
    "    \"\"\"드래그 앤 드롭을 지원하는 커스텀 라벨 위젯\"\"\"\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "        self.setAcceptDrops(True)\n",
    "        self.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "        self.setText(\"여기에 PDF 파일을 드래그 앤 드롭 하거나\\n아래 버튼을 클릭하세요.\")\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QLabel {\n",
    "                border: 2px dashed #aaa;\n",
    "                padding: 20px;\n",
    "                font-size: 14px;\n",
    "                background-color: #f9f9f9;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "    def dragEnterEvent(self, event):\n",
    "        if event.mimeData().hasUrls():\n",
    "            event.acceptProposedAction()\n",
    "        else:\n",
    "            event.ignore()\n",
    "\n",
    "    def dropEvent(self, event):\n",
    "        for url in event.mimeData().urls():\n",
    "            file_path = url.toLocalFile()\n",
    "            if file_path.lower().endswith('.pdf'):\n",
    "                print(f\"드롭된 파일: {file_path}\")\n",
    "                self.parent().upload_file(file_path)\n",
    "                return\n",
    "        print(\"PDF 파일이 아닙니다.\")\n",
    "\n",
    "class RAGClientApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Flask 서버 주소\n",
    "        self.upload_url = \"http://127.0.0.1:5000/upload\"\n",
    "        self.ask_url = \"http://127.0.0.1:5000/ask\"\n",
    "        self.init_ui()\n",
    "\n",
    "    def init_ui(self):\n",
    "        \"\"\"애플리케이션의 전체 UI를 설정합니다.\"\"\"\n",
    "        main_layout = QVBoxLayout()\n",
    "\n",
    "        # --- 1. 파일 업로드 섹션 ---\n",
    "        upload_group_label = QLabel(\"1. PDF 파일 업로드\")\n",
    "        upload_group_label.setStyleSheet(\"font-size: 16px; font-weight: bold; margin-top: 10px;\")\n",
    "        main_layout.addWidget(upload_group_label)\n",
    "        \n",
    "        self.drop_label = DragDropLabel(self)\n",
    "        main_layout.addWidget(self.drop_label)\n",
    "\n",
    "        self.btn_select = QPushButton(\"컴퓨터에서 PDF 파일 선택\")\n",
    "        self.btn_select.clicked.connect(self.open_file_dialog)\n",
    "        main_layout.addWidget(self.btn_select)\n",
    "        \n",
    "        self.status_label = QLabel(\"상태: 대기 중\")\n",
    "        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "        main_layout.addWidget(self.status_label)\n",
    "        \n",
    "        # --- 구분선 ---\n",
    "        separator = QFrame()\n",
    "        separator.setFrameShape(QFrame.Shape.HLine)\n",
    "        separator.setFrameShadow(QFrame.Shadow.Sunken)\n",
    "        main_layout.addWidget(separator)\n",
    "\n",
    "        # --- 2. 질문/답변 섹션 ---\n",
    "        qa_group_label = QLabel(\"2. 질문하기\")\n",
    "        qa_group_label.setStyleSheet(\"font-size: 16px; font-weight: bold; margin-top: 10px;\")\n",
    "        main_layout.addWidget(qa_group_label)\n",
    "\n",
    "        # 질문 입력 레이아웃\n",
    "        question_layout = QHBoxLayout()\n",
    "        self.question_input = QLineEdit()\n",
    "        self.question_input.setPlaceholderText(\"업로드된 PDF에 대해 질문을 입력하세요...\")\n",
    "        question_layout.addWidget(self.question_input)\n",
    "\n",
    "        self.btn_ask = QPushButton(\"질문하기\")\n",
    "        self.btn_ask.clicked.connect(self.ask_question)\n",
    "        question_layout.addWidget(self.btn_ask)\n",
    "        main_layout.addLayout(question_layout)\n",
    "\n",
    "        # 답변 출력창\n",
    "        answer_label = QLabel(\"답변:\")\n",
    "        main_layout.addWidget(answer_label)\n",
    "        \n",
    "        self.answer_output = QTextEdit()\n",
    "        self.answer_output.setReadOnly(True) # 답변은 수정할 수 없도록 설정\n",
    "        self.answer_output.setStyleSheet(\"background-color: #f0f0f0;\")\n",
    "        main_layout.addWidget(self.answer_output)\n",
    "        \n",
    "        # 초기에는 질문 섹션을 비활성화\n",
    "        self.set_qa_section_enabled(False)\n",
    "\n",
    "        self.setLayout(main_layout)\n",
    "        self.setWindowTitle(\"PDF 기반 RAG 질문 답변 시스템\")\n",
    "        self.setGeometry(300, 300, 500, 600)\n",
    "\n",
    "    def set_qa_section_enabled(self, enabled):\n",
    "        \"\"\"질문/답변 섹션의 활성화 상태를 설정합니다.\"\"\"\n",
    "        self.question_input.setEnabled(enabled)\n",
    "        self.btn_ask.setEnabled(enabled)\n",
    "        self.answer_output.setEnabled(enabled)\n",
    "        if not enabled:\n",
    "            self.answer_output.setPlaceholderText(\"PDF 파일을 먼저 업로드해주세요.\")\n",
    "        else:\n",
    "            self.answer_output.setPlaceholderText(\"\")\n",
    "\n",
    "\n",
    "    def open_file_dialog(self):\n",
    "        file_path, _ = QFileDialog.getOpenFileName(self, \"PDF 파일 선택\", \"\", \"PDF Files (*.pdf)\")\n",
    "        if file_path:\n",
    "            self.upload_file(file_path)\n",
    "\n",
    "    def upload_file(self, file_path):\n",
    "        filename = file_path.split('/')[-1]\n",
    "        self.status_label.setText(f\"상태: '{filename}' 업로드 및 처리 중... (파일 크기에 따라 시간이 걸릴 수 있습니다)\")\n",
    "        self.set_qa_section_enabled(False) # 처리 중 다시 비활성화\n",
    "        QApplication.processEvents() # UI가 멈추지 않도록 이벤트 처리\n",
    "\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                files = {'file': (filename, f, 'application/pdf')}\n",
    "                # RAG 처리는 오래 걸릴 수 있으므로 timeout을 넉넉하게 설정\n",
    "                response = requests.post(self.upload_url, files=files, timeout=300)\n",
    "            \n",
    "            response.raise_for_status()\n",
    "            \n",
    "            response_data = response.json()\n",
    "            self.status_label.setText(f\"상태: {response_data.get('message', '업로드 및 처리 완료!')}\")\n",
    "            self.set_qa_section_enabled(True) # 처리가 끝나면 질문 섹션 활성화\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            self.status_label.setText(f\"상태: 업로드 실패 - {e}\")\n",
    "        except Exception as e:\n",
    "            self.status_label.setText(f\"상태: 오류 발생 - {e}\")\n",
    "\n",
    "    def ask_question(self):\n",
    "        question = self.question_input.text().strip()\n",
    "        if not question:\n",
    "            self.answer_output.setText(\"질문을 입력해주세요.\")\n",
    "            return\n",
    "\n",
    "        self.answer_output.setText(\"답변을 생성 중입니다...\")\n",
    "        QApplication.processEvents()\n",
    "\n",
    "        try:\n",
    "            payload = {\"question\": question}\n",
    "            response = requests.post(self.ask_url, json=payload, timeout=60)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            response_data = response.json()\n",
    "            self.answer_output.setText(response_data.get(\"answer\", \"답변을 가져올 수 없습니다.\"))\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            self.answer_output.setText(f\"오류: 서버와 통신할 수 없습니다.\\n{e}\")\n",
    "        except Exception as e:\n",
    "            self.answer_output.setText(f\"알 수 없는 오류가 발생했습니다.\\n{e}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        import requests\n",
    "    except ImportError:\n",
    "        print(\"requests 라이브러리가 필요합니다. 'pip install -r requirements.txt' 명령어로 설치해주세요.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    app = QApplication(sys.argv)\n",
    "    ex = RAGClientApp()\n",
    "    ex.show()\n",
    "    sys.exit(app.exec())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c74d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
