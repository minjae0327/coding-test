{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f272eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨ Gemini models initialized successfully.\n",
      "Upstage API 결과 저장 완료: upstage_output\\manual_result.json\n",
      "✅ Saved element 3 to upstage_output\\md_images\\table_3.png\n",
      "\n",
      "--- 📊 Generating table summary ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minja\\GitHub\\coding-test\\deeplearning\\RAG\\pdf_preprocessor.py:170: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df_list = pd.read_html(f\"<table>{html_content}</table>\", flavor='lxml')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved element 23 to upstage_output\\md_images\\table_23.png\n",
      "\n",
      "--- 📊 Generating table summary ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minja\\GitHub\\coding-test\\deeplearning\\RAG\\pdf_preprocessor.py:170: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df_list = pd.read_html(f\"<table>{html_content}</table>\", flavor='lxml')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved element 34 to upstage_output\\md_images\\table_34.png\n",
      "\n",
      "--- 📊 Generating table summary ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minja\\GitHub\\coding-test\\deeplearning\\RAG\\pdf_preprocessor.py:170: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df_list = pd.read_html(f\"<table>{html_content}</table>\", flavor='lxml')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Successfully generated Markdown file at: upstage_output\\manual_with_descriptions.md\n",
      "upstage_output\\manual_with_descriptions.md\n"
     ]
    }
   ],
   "source": [
    "from pdf_preprocessor import pdf_preprocessor\n",
    "\n",
    "pdf_path = \"datasets/manual.pdf\"\n",
    "\n",
    "pp = pdf_preprocessor()\n",
    "\n",
    "aa = pp.process(pdf_path)\n",
    "print(aa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5e40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨ Gemini models initialized successfully.\n",
      "✅ Saved element 3 to upstage_output\\md_images\\table_3.png\n",
      "\n",
      "--- 📊 Generating table summary ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minja\\AppData\\Local\\Temp\\ipykernel_4336\\2388962276.py:175: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df_list = pd.read_html(f\"<table>{html_content}</table>\", flavor='lxml')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved element 23 to upstage_output\\md_images\\table_23.png\n",
      "\n",
      "--- 📊 Generating table summary ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minja\\AppData\\Local\\Temp\\ipykernel_4336\\2388962276.py:175: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df_list = pd.read_html(f\"<table>{html_content}</table>\", flavor='lxml')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved element 34 to upstage_output\\md_images\\table_34.png\n",
      "\n",
      "--- 📊 Generating table summary ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minja\\AppData\\Local\\Temp\\ipykernel_4336\\2388962276.py:175: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df_list = pd.read_html(f\"<table>{html_content}</table>\", flavor='lxml')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Successfully generated Markdown file at: upstage_output/output_with_descriptions.md\n",
      "\n",
      " Successfully generated Markdown file at: upstage_output/outputs.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# --- Configuration ---\n",
    "JSON_FILE_PATH = \"upstage_output/result.json\"\n",
    "PDF_FILE_PATH = \"datasets/manual.pdf\"\n",
    "MAIN_PATH = \"upstage_output\"\n",
    "IMG_OUTPUT_DIR = \"upstage_output/md_images\"\n",
    "MD_OUTPUT_FILE = \"upstage_output/outputs.md\"\n",
    "IMG_DIR = \"md_images\"\n",
    "DES_MD_OUTPUT_FILE = \"upstage_output/output_with_descriptions.md\"\n",
    "\n",
    "# --- Gemini API Setup ---\n",
    "try:\n",
    "    # Load API key from environment variable\n",
    "    GOOGLE_API_KEY = os.environ[\"GOOGLE_API_KEY\"]\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    \n",
    "    # Initialize Gemini models\n",
    "    text_model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "    vision_model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "    print(\"✨ Gemini models initialized successfully.\")\n",
    "    \n",
    "except KeyError:\n",
    "    print(\"🛑 ERROR: GOOGLE_API_KEY environment variable not set.\")\n",
    "    print(\"Please set your API key to proceed.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"🛑 ERROR: Failed to initialize Gemini models - {e}\")\n",
    "    exit()\n",
    "\n",
    "# ==============================================================================\n",
    "#  YOUR PROVIDED GEMINI FUNCTIONS (with minor modifications for integration)\n",
    "# ==============================================================================\n",
    "\n",
    "def generate_image_description_with_gemini(image_path):\n",
    "    \"\"\"\n",
    "    Analyzes an image file using the Gemini API and generates a structured description.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 🖼️ Generating image description for: {os.path.basename(image_path)} ---\")\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: File not found - {image_path}\")\n",
    "        return \"오류: 이미지 파일을 찾을 수 없어 설명을 생성하지 못했습니다.\"\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to open image file - {e}\")\n",
    "        return \"오류: 이미지 파일을 열 수 없어 설명을 생성하지 못했습니다.\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    당신은 이미지를 분석하여 검색 시스템(RAG)을 위한 메타데이터를 생성하는 AI 전문가입니다.\n",
    "    첨부된 이미지를 RAG 시스템에서 효과적으로 검색할 수 있도록, 아래 [분석 지침]에 따라 한글로 상세히 설명해주세요.\n",
    "\n",
    "    [분석 지침]\n",
    "    1.  **종합 요약 (1~2문장)**: 이미지의 핵심 주제와 내용을 간결하게 요약해주세요.\n",
    "    2.  **주요 구성요소 및 객체**: 이미지에 포함된 중요한 사물, 인물, 아이콘, 그래프 요소 등을 구체적으로 나열해주세요.\n",
    "    3.  **이미지 내 텍스트 (OCR)**: 이미지에 보이는 모든 텍스트를 그대로 옮겨 적어주세요. 텍스트가 없다면 '텍스트 없음'이라고 명시해주세요.\n",
    "    4.  **시각적 특징 및 스타일**: 이미지의 전체적인 색상 톤, 구도, 스타일, 분위기 등을 설명해주세요.\n",
    "    5.  **핵심 키워드 (쉼표로 구분)**: 검색에 사용될 만한 핵심 키워드를 5개 이상 나열해주세요.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = vision_model.generate_content([prompt, img])\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during Gemini image analysis: {e}\")\n",
    "        return \"오류: 이미지 설명을 생성하지 못했습니다.\"\n",
    "\n",
    "\n",
    "def generate_table_summary_with_gemini(table_csv_str):\n",
    "    \"\"\"\n",
    "    Analyzes CSV string data using the Gemini API and generates a summary report.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 📊 Generating table summary ---\")\n",
    "    prompt = f\"\"\"\n",
    "    당신은 최고의 데이터 분석가입니다. 당신의 임무는 주어진 CSV 형식의 데이터를 구조적으로 분석하고, 비전문가도 이해하기 쉽게 핵심 내용을 요약하는 것입니다.\n",
    "\n",
    "    아래 [분석 지침]과 [CSV 데이터]를 보고 상세한 분석 보고서를 한국어로 작성해 주세요.\n",
    "\n",
    "    [분석 지침]\n",
    "    1.  **표의 주제**: 이 표가 무엇에 대한 데이터인지 한 문장으로 명확하게 정의하세요.\n",
    "    2.  **구조 설명**: 각 행(row)과 열(column)이 무엇을 나타내는지 설명하세요.\n",
    "    3.  **핵심 정보 및 수치**: 표에서 가장 중요한 핵심 정보를 3~5가지 항목으로 요약하세요. 구체적인 수치, 비율(%), 조건, 기간 등을 반드시 포함하세요.\n",
    "    4.  **패턴 또는 특이사항 (선택 사항)**: 데이터에서 발견할 수 있는 패턴, 경향성 또는 특이점이 있다면 언급하세요.\n",
    "    5.  **참고**: 데이터는 행 또는 열들의 결합으로 되어있을 수도 있습니다. 행과 열 모두 신중히 보세요.\n",
    "\n",
    "    [CSV 데이터]\n",
    "    ---\n",
    "    {table_csv_str}\n",
    "    ---\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = text_model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during Gemini table analysis: {e}\")\n",
    "        return \"오류: 테이블 요약을 생성하지 못했습니다.\"\n",
    "\n",
    "# ==============================================================================\n",
    "#  ORIGINAL SCRIPT LOGIC (modified for Gemini integration)\n",
    "# ==============================================================================\n",
    "\n",
    "def convert_html_to_markdown(element):\n",
    "    html_content = element.get(\"content\", {}).get(\"html\", \"\")\n",
    "    if not html_content:\n",
    "        return \"\"\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    text = soup.get_text().strip()\n",
    "\n",
    "    category = element.get(\"category\")\n",
    "\n",
    "    # Format text based on its category\n",
    "    if category == \"heading1\":\n",
    "        # Check font size to determine heading level (#, ##, ###)\n",
    "        style = soup.find().get('style', '')\n",
    "        font_size = 0\n",
    "        if 'font-size' in style:\n",
    "            font_size = int(''.join(filter(str.isdigit, style.split('font-size:')[1])))\n",
    "\n",
    "        if font_size >= 22:\n",
    "            return f\"# {text}\\n\"\n",
    "        elif font_size >= 20:\n",
    "            return f\"## {text}\\n\"\n",
    "        else:\n",
    "            return f\"### {text}\\n\"\n",
    "    elif category in [\"paragraph\", \"list\"]:\n",
    "        # Add extra newline for better spacing\n",
    "        return f\"{text}\\n\"\n",
    "    elif category == \"footer\":\n",
    "        return f\"_{text}_\\n\" # Italicize footer text\n",
    "    else:\n",
    "        return f\"{text}\\n\"\n",
    "\n",
    "\n",
    "def crop_element_as_image(pdf_doc, element, output_dir):\n",
    "    page_num = element.get(\"page\") - 1\n",
    "    if page_num < 0:\n",
    "        return None\n",
    "\n",
    "    page = pdf_doc.load_page(page_num)\n",
    "    page_width, page_height = page.rect.width, page.rect.height\n",
    "\n",
    "    # Coordinates are normalized, so convert them to absolute points\n",
    "    coords = element.get(\"coordinates\", [])\n",
    "    if not coords or len(coords) < 3:\n",
    "        return None\n",
    "\n",
    "    # Get the top-left (x0, y0) and bottom-right (x1, y1) points\n",
    "    x0 = coords[0]['x'] * page_width\n",
    "    y0 = coords[0]['y'] * page_height\n",
    "    x1 = coords[2]['x'] * page_width\n",
    "    y1 = coords[2]['y'] * page_height\n",
    "\n",
    "    # Define the clipping area and get the pixmap\n",
    "    clip_rect = fitz.Rect(x0, y0, x1, y1)\n",
    "    # Use a high DPI for better image quality\n",
    "    pix = page.get_pixmap(clip=clip_rect, dpi=200)\n",
    "\n",
    "    # Define the image path and save it\n",
    "    img_filename = f\"{element.get('category')}_{element.get('id')}.png\"\n",
    "    img_path = os.path.join(output_dir, img_filename)\n",
    "    img_path_to_store = os.path.join(MAIN_PATH, img_path)\n",
    "    pix.save(img_path_to_store)\n",
    "\n",
    "    print(f\"✅ Saved element {element.get('id')} to {img_path_to_store}\")\n",
    "    return img_path\n",
    "\n",
    "\n",
    "def html_table_to_csv_string(html_content):\n",
    "    \"\"\"Converts an HTML table into a CSV formatted string.\"\"\"\n",
    "    try:\n",
    "        # pandas.read_html returns a list of DataFrames\n",
    "        df_list = pd.read_html(f\"<table>{html_content}</table>\", flavor='lxml')\n",
    "        if not df_list:\n",
    "            return \"\"\n",
    "        # We assume the first table found is the correct one\n",
    "        df = df_list[0]\n",
    "        # Clean up NaN values which can occur from merged cells\n",
    "        df.fillna('', inplace=True)\n",
    "        return df.to_csv(index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not parse HTML table: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process the JSON and generate the Markdown file.\n",
    "    \"\"\"\n",
    "    # 1. Check for required files\n",
    "    if not os.path.exists(JSON_FILE_PATH) or not os.path.exists(PDF_FILE_PATH):\n",
    "        print(f\"Error: Make sure '{JSON_FILE_PATH}' and '{PDF_FILE_PATH}' exist.\")\n",
    "        return\n",
    "\n",
    "    # 2. Create the output directory for images\n",
    "    os.makedirs(IMG_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # 3. Load the JSON data\n",
    "    with open(JSON_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 4. Open the PDF document\n",
    "    pdf_doc = fitz.open(PDF_FILE_PATH)\n",
    "    markdown_parts = []\n",
    "    description_markdown_parts = []\n",
    "\n",
    "    # 5. Process each element\n",
    "    elements = data.get(\"elements\", [])\n",
    "    if not elements:\n",
    "        print(\"no elements\")\n",
    "        return\n",
    "        \n",
    "    for element in elements:\n",
    "        category = element.get(\"category\")\n",
    "        description = \"\"\n",
    "        \n",
    "        if category in [\"table\", \"figure\", \"chart\"]: # You can add other types here\n",
    "            img_path = crop_element_as_image(pdf_doc, element, IMG_DIR)\n",
    "            if img_path:\n",
    "                markdown_parts.append(f\"![{category} {element.get('id')}]({img_path})\\n\")\n",
    "                \n",
    "            if category == \"table\":\n",
    "                html_content = element.get(\"content\", {}).get(\"html\", \"\")\n",
    "                if html_content:\n",
    "                    csv_str = html_table_to_csv_string(html_content)\n",
    "                    if csv_str:\n",
    "                        description = generate_table_summary_with_gemini(csv_str)\n",
    "                        \n",
    "            else:\n",
    "                description = generate_image_description_with_gemini(img_path)\n",
    "        \n",
    "        else:\n",
    "            markdown_text = convert_html_to_markdown(element)\n",
    "            markdown_parts.append(markdown_text)\n",
    "            description_markdown_parts.append(markdown_text)\n",
    "            \n",
    "        if description:\n",
    "            formatted_description = \"\\n> \" + description.replace(\"\\n\", \"\\n> \") + \"\\n\"\n",
    "            description_markdown_parts.append(formatted_description)\n",
    "\n",
    "\n",
    "    with open(DES_MD_OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\".join(description_markdown_parts))\n",
    "\n",
    "    with open(MD_OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\".join(markdown_parts))\n",
    "\n",
    "    print(f\"\\n Successfully generated Markdown file at: {DES_MD_OUTPUT_FILE}\")\n",
    "    print(f\"\\n Successfully generated Markdown file at: {MD_OUTPUT_FILE}\")\n",
    "\n",
    "    # 7. Clean up\n",
    "    pdf_doc.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb600e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414a523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계: 미디어 정보 미리 추출 중 (이미지: pdfplumber, 테이블: camelot)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 0개의 이미지 정보를 찾았습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 2개의 테이블 정보를 찾았습니다.\n",
      "2단계: unstructured로 문서 구조 분석 중 (hi_res 전략 사용)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3단계: 텍스트, 테이블, 이미지를 통합하고 AI로 내용을 보강합니다...\n",
      "\n",
      "--- 테이블 요약 생성 시작 ---\n",
      "\n",
      "--- 테이블 요약 생성 시작 ---\n",
      "4단계: 최종 결과 정리 및 저장...\n",
      "\n",
      "--- 작업 완료 ---\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Gemini AI 클라이언트 및 유틸리티 함수 정의 ---\n",
    "\n",
    "# 여기에 Gemini API 키를 설정하세요.\n",
    "# 환경 변수에서 불러오는 것을 권장합니다.\n",
    "# from google.colab import userdata\n",
    "# GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "# genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "genai.configure()\n",
    "\n",
    "# 사용할 Gemini 모델 설정\n",
    "# 요청하신 gemini-2.5pro는 아직 출시되지 않았으므로, gemini-1.5-pro-latest를 사용합니다.\n",
    "# 추후 모델이 출시되면 이 부분만 수정하면 됩니다.\n",
    "vision_model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "text_model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "\n",
    "def generate_image_description_with_gemini(image_path):\n",
    "    \"\"\"\n",
    "    Gemini API를 사용하여 이미지 파일을 분석하고 구조화된 설명을 생성합니다.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 이미지 설명 생성 시작: {os.path.basename(image_path)} ---\")\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"오류: 파일을 찾을 수 없습니다 - {image_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"오류: 이미지 파일 열기 실패 - {e}\")\n",
    "        return None\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    당신은 이미지를 분석하여 검색 시스템(RAG)을 위한 메타데이터를 생성하는 AI 전문가입니다.\n",
    "    첨부된 이미지를 RAG 시스템에서 효과적으로 검색할 수 있도록, 아래 [분석 지침]에 따라 한글로 상세히 설명해주세요.\n",
    "\n",
    "    [분석 지침]\n",
    "    1.  **종합 요약 (1~2문장)**: 이미지의 핵심 주제와 내용을 간결하게 요약해주세요.\n",
    "    2.  **주요 구성요소 및 객체**: 이미지에 포함된 중요한 사물, 인물, 아이콘, 그래프 요소 등을 구체적으로 나열해주세요.\n",
    "    3.  **이미지 내 텍스트 (OCR)**: 이미지에 보이는 모든 텍스트를 그대로 옮겨 적어주세요. 텍스트가 없다면 '텍스트 없음'이라고 명시해주세요.\n",
    "    4.  **시각적 특징 및 스타일**: 이미지의 전체적인 색상 톤, 구도, 스타일, 분위기 등을 설명해주세요.\n",
    "    5.  **핵심 키워드 (쉼표로 구분)**: 검색에 사용될 만한 핵심 키워드를 5개 이상 나열해주세요.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = vision_model.generate_content([prompt, img])\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Gemini 이미지 분석 중 오류 발생: {e}\")\n",
    "        return \"오류: 이미지 설명을 생성하지 못했습니다.\"\n",
    "\n",
    "\n",
    "def generate_table_summary_with_gemini(table_csv_str):\n",
    "    \"\"\"\n",
    "    Gemini API를 사용하여 CSV 문자열 데이터를 분석하고 요약 보고서를 생성합니다.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 테이블 요약 생성 시작 ---\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    당신은 최고의 데이터 분석가입니다. 당신의 임무는 주어진 CSV 형식의 데이터를 구조적으로 분석하고, 비전문가도 이해하기 쉽게 핵심 내용을 요약하는 것입니다.\n",
    "\n",
    "    아래 [분석 지침]과 [CSV 데이터]를 보고 상세한 분석 보고서를 한국어로 작성해 주세요.\n",
    "\n",
    "    [분석 지침]\n",
    "    1.  **표의 주제**: 이 표가 무엇에 대한 데이터인지 한 문장으로 명확하게 정의하세요.\n",
    "    2.  **구조 설명**: 각 행(row)과 열(column)이 무엇을 나타내는지 설명하세요.\n",
    "    3.  **핵심 정보 및 수치**: 표에서 가장 중요한 핵심 정보를 3~5가지 항목으로 요약하세요. 구체적인 수치, 비율(%), 조건, 기간 등을 반드시 포함하세요.\n",
    "    4.  **패턴 또는 특이사항 (선택 사항)**: 데이터에서 발견할 수 있는 패턴, 경향성 또는 특이점이 있다면 언급하세요.\n",
    "    5.  **참고**: 데이터는 행 또는 열들의 결합으로 되어있을 수도 있습니다. 행과 열 모두 신중히 보세요.\n",
    "\n",
    "    [CSV 데이터]\n",
    "    ---\n",
    "    {table_csv_str}\n",
    "    ---\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = text_model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Gemini 테이블 분석 중 오류 발생: {e}\")\n",
    "        return \"오류: 테이블 요약을 생성하지 못했습니다.\"\n",
    "\n",
    "\n",
    "def process_table_with_ai_camelot(table_df, output_dir, page_num, table_index):\n",
    "    \"\"\"camelot으로 추출한 테이블 DataFrame을 처리하고 Gemini AI 요약을 생성합니다.\"\"\"\n",
    "    try:\n",
    "        table_filename = f\"p{page_num}_tbl{table_index}.csv\"\n",
    "        table_path = os.path.join(output_dir, \"tables\", table_filename)\n",
    "        table_df.to_csv(table_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "        # AI 요약을 위해 DataFrame을 CSV 문자열로 변환\n",
    "        csv_string = table_df.to_csv(index=False)\n",
    "        table_description = generate_table_summary_with_gemini(csv_string)\n",
    "\n",
    "        return {\"path\": table_path, \"page\": page_num, \"dataframe\": table_df, \"description\": table_description}\n",
    "    except Exception as e:\n",
    "        print(f\"  - 테이블 처리 중 오류 발생: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_image_with_ai(image_data, output_dir, page_num, image_index):\n",
    "    \"\"\"pdfplumber로 추출한 이미지를 처리하고 Gemini AI 설명을 생성합니다.\"\"\"\n",
    "    try:\n",
    "        image_bytes = image_data['stream'].get_data()\n",
    "        kind = filetype.guess(image_bytes)\n",
    "        image_ext = kind.extension if kind else \"png\"\n",
    "        image_filename = f\"p{page_num}_img{image_index}.{image_ext}\"\n",
    "        image_path = os.path.join(output_dir, \"images\", image_filename)\n",
    "\n",
    "        with open(image_path, \"wb\") as img_file:\n",
    "            img_file.write(image_bytes)\n",
    "\n",
    "        image_description = generate_image_description_with_gemini(image_path)\n",
    "        return {\"path\": image_path, \"page\": page_num, \"description\": image_description}\n",
    "    except Exception as e:\n",
    "        print(f\"  - 이미지 처리 중 오류 발생: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 2. camelot을 사용하도록 수정한 메인 함수 ---\n",
    "\n",
    "def create_integrated_markdown_from_camelot(pdf_path):\n",
    "    output_dir = os.path.basename(pdf_path).split(\".\")[0]\n",
    "    os.makedirs(os.path.join(output_dir, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"tables\"), exist_ok=True)\n",
    "\n",
    "    # 1단계: 미디어 정보 미리 추출\n",
    "    print(\"1단계: 미디어 정보 미리 추출 중 (이미지: pdfplumber, 테이블: camelot)...\")\n",
    "\n",
    "    # pdfplumber로 이미지 추출\n",
    "    images_by_page = defaultdict(list)\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            images_by_page[page.page_number].extend(page.images)\n",
    "    print(f\"총 {sum(len(v) for v in images_by_page.values())}개의 이미지 정보를 찾았습니다.\")\n",
    "\n",
    "    # camelot으로 테이블 추출\n",
    "    tables_by_page = defaultdict(list)\n",
    "    try:\n",
    "        tables = camelot.read_pdf(pdf_path, pages='all', flavor='lattice', suppress_stdout=True)\n",
    "        for table in tables:\n",
    "            tables_by_page[table.page].append(table.df)\n",
    "        print(f\"총 {sum(len(v) for v in tables_by_page.values())}개의 테이블 정보를 찾았습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Camelot으로 테이블 추출 중 오류 발생: {e}\")\n",
    "\n",
    "    # 2단계: unstructured로 PDF 요소 순서대로 파티셔닝\n",
    "    print(\"2단계: unstructured로 문서 구조 분석 중 (hi_res 전략 사용)...\")\n",
    "    elements = partition_pdf(filename=pdf_path, infer_table_structure=True, strategy=\"hi_res\")\n",
    "\n",
    "    # 3단계: 요소 순회하며 최종 마크다운 및 데이터 생성\n",
    "    print(\"3단계: 텍스트, 테이블, 이미지를 통합하고 AI로 내용을 보강합니다...\")\n",
    "    final_markdown_parts = []\n",
    "    extracted_tables = []\n",
    "    extracted_images = []\n",
    "    page_counters = defaultdict(lambda: {'tables': 0, 'images': 0})\n",
    "\n",
    "    for el in elements:\n",
    "        page_num = el.metadata.page_number\n",
    "\n",
    "        if \"unstructured.documents.elements.Table\" in str(type(el)):\n",
    "            table_index = page_counters[page_num]['tables']\n",
    "            if table_index < len(tables_by_page[page_num]):\n",
    "                raw_table_df = tables_by_page[page_num][table_index]\n",
    "                table_data = process_table_with_ai_camelot(raw_table_df, output_dir, page_num, table_index)\n",
    "                if table_data:\n",
    "                    placeholder = f\"\\n\\n[[-- TABLE: Page {page_num}, Index {table_index} | Path: {table_data['path']} --]]\\n**표 요약:** {table_data['description']}\\n\\n\"\n",
    "                    final_markdown_parts.append(placeholder)\n",
    "                    extracted_tables.append(table_data)\n",
    "                    page_counters[page_num]['tables'] += 1\n",
    "\n",
    "        elif \"unstructured.documents.elements.Image\" in str(type(el)):\n",
    "            image_index = page_counters[page_num]['images']\n",
    "            if image_index < len(images_by_page[page_num]):\n",
    "                raw_image_data = images_by_page[page_num][image_index]\n",
    "                image_data = process_image_with_ai(raw_image_data, output_dir, page_num, image_index)\n",
    "                if image_data:\n",
    "                    relative_path = os.path.relpath(image_data['path'], output_dir).replace(os.sep, '/')\n",
    "                    md_link = f\"\\n\\n![{image_data['description']}]({relative_path})\\n\\n\"\n",
    "                    final_markdown_parts.append(md_link)\n",
    "                    extracted_images.append(image_data)\n",
    "                    page_counters[page_num]['images'] += 1\n",
    "\n",
    "        else:\n",
    "            final_markdown_parts.append(el.text)\n",
    "\n",
    "    # 4단계: 최종 결과 정리 및 저장\n",
    "    print(\"4단계: 최종 결과 정리 및 저장...\")\n",
    "    final_markdown = \"\\n\\n\".join(final_markdown_parts)\n",
    "    output_filename = os.path.join(output_dir, \"integrated_markdown_gemini.md\")\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(final_markdown)\n",
    "\n",
    "    print(\"\\n--- 작업 완료 ---\")\n",
    "    return {\n",
    "        \"output_dir\": output_dir,\n",
    "        \"integrated_markdown_file\": output_filename,\n",
    "        \"images\": extracted_images,\n",
    "        \"tables\": extracted_tables,\n",
    "        \"integrated_markdown_content\": final_markdown,\n",
    "    }\n",
    "\n",
    "# --- 코드 실행 예제 ---\n",
    "# 아래 코드 실행 전, 'YOUR_GOOGLE_API_KEY' 부분을 실제 키로 변경해야 합니다.\n",
    "pdf_path = \"datasets/manual.pdf\"  # 실제 PDF 파일 경로로 변경해주세요.\n",
    "extracted_data = create_integrated_markdown_from_camelot(pdf_path)\n",
    "\n",
    "# # 결과 확인\n",
    "# print(f\"\\nAI 요약/설명이 포함된 통합 마크다운 파일이 '{extracted_data['integrated_markdown_file']}'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79536e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b36c9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계: 미디어 정보 미리 추출 중 (이미지: pdfplumber, 테이블: camelot)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 0개의 이미지 정보를 찾았습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 2개의 테이블 정보를 찾았습니다.\n",
      "2단계: unstructured로 문서 구조 분석 중 (hi_res 전략 사용)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3단계: 텍스트, 테이블, 이미지를 통합하고 AI로 내용을 보강합니다...\n",
      "\n",
      "--- 테이블 요약 생성 시작 ---\n",
      "1. 'temp_table.csv' 파일 업로드 중...\n",
      "   - 파일 ID: file-AetHJgnrsTitC8hZVGQDnn\n",
      "2. 분석용 어시스턴트 생성 중...\n",
      "  - 테이블 처리 중 오류 발생: Error code: 400 - {'error': {'message': \"The requested model 'o3-mini' cannot be used with the 'code_interpreter' tool.\", 'type': 'invalid_request_error', 'param': 'model', 'code': 'unsupported_model'}}\n",
      "\n",
      "--- 테이블 요약 생성 시작 ---\n",
      "1. 'temp_table.csv' 파일 업로드 중...\n",
      "   - 파일 ID: file-4598CnS6fcgTnjV7WGHwFq\n",
      "2. 분석용 어시스턴트 생성 중...\n",
      "  - 테이블 처리 중 오류 발생: Error code: 400 - {'error': {'message': \"The requested model 'o3-mini' cannot be used with the 'code_interpreter' tool.\", 'type': 'invalid_request_error', 'param': 'model', 'code': 'unsupported_model'}}\n",
      "4단계: 최종 결과 정리 및 저장...\n",
      "\n",
      "--- 작업 완료 ---\n"
     ]
    }
   ],
   "source": [
    "# # --- 1. AI 클라이언트 및 유틸리티 함수 정의 (기존과 동일) ---\n",
    "# client = OpenAI() # API 키는 환경 변수에 설정 권장\n",
    "\n",
    "# def encode_image_to_base64(image_path):\n",
    "#     with open(image_path, \"rb\") as image_file:\n",
    "#         return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# def run_assistant_on_file(file_path, assistant_instructions, user_prompt_content):\n",
    "#     \"\"\"\n",
    "#     파일을 업로드하고 지정된 지시에 따라 Assistant를 실행한 후 결과를 반환하는 범용 함수입니다.\n",
    "#     \"\"\"\n",
    "#     print(f\"1. '{os.path.basename(file_path)}' 파일 업로드 중...\")\n",
    "#     try:\n",
    "#         file_object = client.files.create(\n",
    "#             file=open(file_path, \"rb\"),\n",
    "#             purpose=\"assistants\"\n",
    "#         )\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"오류: 파일을 찾을 수 없습니다 - {file_path}\")\n",
    "#         return None\n",
    "#     print(f\"   - 파일 ID: {file_object.id}\")\n",
    "    \n",
    "#     # 2. 어시스턴트 생성\n",
    "#     print(\"2. 분석용 어시스턴트 생성 중...\")\n",
    "#     assistant = client.beta.assistants.create(\n",
    "#         name=\"전문 분석가\",\n",
    "#         instructions=assistant_instructions,\n",
    "#         model=\"gpt-4o\",\n",
    "#         tools=[{\"type\": \"code_interpreter\"}]\n",
    "#     )\n",
    "    \n",
    "#     # 3. 대화를 위한 스레드 생성\n",
    "#     print(\"3. 대화 스레드 생성 중...\")\n",
    "#     thread = client.beta.threads.create()\n",
    "#     print(f\"   - 스레드 ID: {thread.id}\")\n",
    "\n",
    "#     # 4. 스레드에 메시지 및 파일 추가\n",
    "#     print(\"4. 분석 요청 메시지 및 파일 추가 중...\")\n",
    "#     client.beta.threads.messages.create(\n",
    "#         thread_id=thread.id,\n",
    "#         role=\"user\",\n",
    "#         content=user_prompt_content,\n",
    "#         attachments=[{\"file_id\": file_object.id, \"tools\": [{\"type\": \"code_interpreter\"}]}]\n",
    "#     )\n",
    "    \n",
    "#     # 5. 어시스턴트 실행\n",
    "#     print(\"5. 어시스턴트 실행 및 분석 시작...\")\n",
    "#     run = client.beta.threads.runs.create(\n",
    "#         thread_id=thread.id,\n",
    "#         assistant_id=assistant.id\n",
    "#     )\n",
    "\n",
    "#     # 6. 실행 완료 대기\n",
    "#     while run.status not in [\"completed\", \"failed\"]:\n",
    "#         run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "#         print(f\"   - 현재 상태: {run.status}\")\n",
    "#         time.sleep(3)\n",
    "\n",
    "#     # 7. 결과 처리 및 리소스 정리\n",
    "#     summary = None\n",
    "#     if run.status == \"completed\":\n",
    "#         print(\"6. 분석 완료. 결과 가져오는 중...\")\n",
    "#         messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "#         for message in messages.data:\n",
    "#             if message.role == \"assistant\":\n",
    "#                 summary = message.content[0].text.value\n",
    "#                 break\n",
    "#     else:\n",
    "#         print(f\"오류: 분석 실패 - {run.last_error}\")\n",
    "\n",
    "#     # 생성된 리소스 정리\n",
    "#     print(\"7. 생성된 리소스 정리 중...\")\n",
    "#     try:\n",
    "#         client.beta.assistants.delete(assistant.id)\n",
    "#         client.files.delete(file_object.id)\n",
    "#         client.beta.threads.delete(thread.id)\n",
    "#         print(\"   - 리소스 정리 완료.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"   - 리소스 정리 중 오류 발생: {e}\")\n",
    "\n",
    "#     return summary\n",
    "\n",
    "\n",
    "# def generate_image_description_with_assistant(image_path):\n",
    "#     \"\"\"\n",
    "#     Assistant API를 사용하여 이미지 파일을 분석하고 구조화된 설명을 생성합니다.\n",
    "#     \"\"\"\n",
    "#     print(f\"\\n--- 이미지 설명 생성 시작: {os.path.basename(image_path)} ---\")\n",
    "#     assistant_instructions = \"\"\"\n",
    "#     당신은 이미지를 분석하여 검색 시스템(RAG)을 위한 메타데이터를 생성하는 AI 전문가입니다.\n",
    "#     주어진 이미지의 모든 시각적, 텍스트적 요소를 추출하여 구조화된 설명을 제공하는 임무를 맡았습니다.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     user_prompt = f\"\"\"\n",
    "#     첨부된 이미지를 RAG 시스템에서 효과적으로 검색할 수 있도록, 아래 [분석 지침]에 따라 한글로 상세히 설명해주세요.\n",
    "\n",
    "#     [분석 지침]\n",
    "#     1.  **종합 요약 (1~2문장)**: 이미지의 핵심 주제와 내용을 간결하게 요약해주세요.\n",
    "#     2.  **주요 구성요소 및 객체**: 이미지에 포함된 중요한 사물, 인물, 아이콘, 그래프 요소 등을 구체적으로 나열해주세요.\n",
    "#     3.  **이미지 내 텍스트 (OCR)**: 이미지에 보이는 모든 텍스트를 그대로 옮겨 적어주세요. 텍스트가 없다면 '텍스트 없음'이라고 명시해주세요.\n",
    "#     4.  **시각적 특징 및 스타일**: 이미지의 전체적인 색상 톤, 구도, 스타일, 분위기 등을 설명해주세요.\n",
    "#     5.  **핵심 키워드 (쉼표로 구분)**: 검색에 사용될 만한 핵심 키워드를 5개 이상 나열해주세요.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     return run_assistant_on_file(image_path, assistant_instructions, user_prompt)\n",
    "\n",
    "# def generate_table_summary_with_assistant(table_csv_str, temp_file_path=\"temp_table.csv\"):\n",
    "#     \"\"\"\n",
    "#     Assistant API를 사용하여 CSV 문자열 데이터를 분석하고 요약 보고서를 생성합니다.\n",
    "#     \"\"\"\n",
    "#     print(f\"\\n--- 테이블 요약 생성 시작 ---\")\n",
    "    \n",
    "#     # CSV 문자열을 임시 파일로 저장\n",
    "#     try:\n",
    "#         with open(temp_file_path, 'w', encoding='utf-8') as f:\n",
    "#             f.write(table_csv_str)\n",
    "#     except Exception as e:\n",
    "#         print(f\"오류: 임시 CSV 파일 생성 실패 - {e}\")\n",
    "#         return None\n",
    "\n",
    "#     assistant_instructions = \"\"\"\n",
    "#     당신은 최고의 데이터 분석가입니다. 당신의 임무는 CSV 형식의 데이터를 구조적으로 분석하고, 비전문가도 이해하기 쉽게 핵심 내용을 요약하는 것입니다.\n",
    "#     항상 다음 분석 절차를 엄격히 준수하여 답변을 생성해 주세요.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     user_prompt = f\"\"\"\n",
    "#     첨부된 CSV 데이터를 보고 아래 [분석 지침]에 따라 상세한 분석 보고서를 작성해 주세요.\n",
    "\n",
    "#     [분석 지침]\n",
    "#     1.  **표의 주제**: 이 표가 무엇에 대한 데이터인지 한 문장으로 명확하게 정의하세요.\n",
    "#     2.  **구조 설명**: 각 행(row)과 열(column)이 무엇을 나타내는지 설명하세요.\n",
    "#     3.  **핵심 정보 및 수치**: 표에서 가장 중요한 핵심 정보를 3~5가지 항목으로 요약하세요. 구체적인 수치, 비율(%), 조건, 기간 등을 반드시 포함하세요.\n",
    "#     4.  **패턴 또는 특이사항 (선택 사항)**: 데이터에서 발견할 수 있는 패턴, 경향성 또는 특이점이 있다면 언급하세요.\n",
    "#     5.  **참고**: 데이터는 행 또는 열들의 결합으로 되어있을 수도 있습니다. 행과 열 모두 신중히 보세요.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # user_prompt = \"\"\"\n",
    "#     # \"첨부된 CSV 파일을 분석해서 다음 항목에 따라 보고서를 작성해 주세요:\n",
    "#     # \\n1. 표의 주제\\n2. 구조(행, 열) 설명\\n3. 핵심 정보 및 수치 요약\\n4. 데이터 패턴 또는 특이사항\\n\\n이 보고서는 한국어로 작성되어야 합니다.\",\n",
    "#     # \"\"\"\n",
    "    \n",
    "#     summary = run_assistant_on_file(temp_file_path, assistant_instructions, user_prompt)\n",
    "    \n",
    "#     # 임시 파일 삭제\n",
    "#     if os.path.exists(temp_file_path):\n",
    "#         os.remove(temp_file_path)\n",
    "        \n",
    "#     return summary\n",
    "\n",
    "\n",
    "# def process_table_with_ai_camelot(table_df, output_dir, page_num, table_index):\n",
    "#     \"\"\"camelot으로 추출한 테이블 DataFrame을 처리하고 AI 요약을 생성합니다.\"\"\"\n",
    "#     try:\n",
    "#         df = table_df\n",
    "#         table_filename = f\"p{page_num}_tbl{table_index}.csv\"\n",
    "#         table_path = os.path.join(output_dir, \"tables\", table_filename)\n",
    "#         df.to_csv(table_path, index=False, encoding=\"utf-8-sig\")\n",
    "        \n",
    "#         # AI 요약을 위해 DataFrame을 CSV 문자열로 변환\n",
    "#         csv_string = df.to_csv(index=False)\n",
    "#         table_description = generate_table_summary_with_assistant(csv_string)\n",
    "        \n",
    "#         return {\"path\": table_path, \"page\": page_num, \"dataframe\": df, \"description\": table_description}\n",
    "#     except Exception as e:\n",
    "#         print(f\"  - 테이블 처리 중 오류 발생: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # process_image_with_ai 함수는 기존과 동일하게 pdfplumber를 사용하므로 변경 없음\n",
    "# def process_image_with_ai(image_data, output_dir, page_num, image_index):\n",
    "#     try:\n",
    "#         image_bytes = image_data['stream'].get_data()\n",
    "#         kind = filetype.guess(image_bytes)\n",
    "#         image_ext = kind.extension if kind else \"png\"\n",
    "#         image_filename = f\"p{page_num}_img{image_index}.{image_ext}\"\n",
    "#         image_path = os.path.join(output_dir, \"images\", image_filename)\n",
    "#         with open(image_path, \"wb\") as img_file:\n",
    "#             img_file.write(image_bytes)\n",
    "#         image_description = generate_image_description_with_assistant(image_path)\n",
    "#         return {\"path\": image_path, \"page\": page_num, \"description\": image_description}\n",
    "#     except Exception as e:\n",
    "#         print(f\"  - 이미지 처리 중 오류 발생: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # --- 3. camelot을 사용하도록 수정한 메인 함수 ---\n",
    "\n",
    "# def create_integrated_markdown_from_camelot(pdf_path):\n",
    "#     output_dir = os.path.basename(pdf_path).split(\".\")[0]\n",
    "#     os.makedirs(os.path.join(output_dir, \"images\"), exist_ok=True)\n",
    "#     os.makedirs(os.path.join(output_dir, \"tables\"), exist_ok=True)\n",
    "\n",
    "#     # 1단계: pdfplumber로 이미지, camelot으로 테이블 미리 추출\n",
    "#     print(\"1단계: 미디어 정보 미리 추출 중 (이미지: pdfplumber, 테이블: camelot)...\")\n",
    "    \n",
    "#     # pdfplumber로 이미지 추출\n",
    "#     images_by_page = defaultdict(list)\n",
    "#     with pdfplumber.open(pdf_path) as pdf:\n",
    "#         for page in pdf.pages:\n",
    "#             images_by_page[page.page_number].extend(page.images)\n",
    "#     print(f\"총 {sum(len(v) for v in images_by_page.values())}개의 이미지 정보를 찾았습니다.\")\n",
    "\n",
    "#     # camelot으로 테이블 추출\n",
    "#     # flavor='lattice'는 선이 있는 표에 적합, 선이 없는 표는 'stream' 사용\n",
    "#     tables_by_page = defaultdict(list)\n",
    "#     try:\n",
    "#         tables = camelot.read_pdf(pdf_path, pages='all', flavor='lattice', suppress_stdout=True)\n",
    "#         for table in tables:\n",
    "#             tables_by_page[table.page].append(table.df)\n",
    "#         print(f\"총 {sum(len(v) for v in tables_by_page.values())}개의 테이블 정보를 찾았습니다.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Camelot으로 테이블 추출 중 오류 발생: {e}\")\n",
    "\n",
    "#     # 2단계: unstructured로 PDF 요소 순서대로 파티셔닝 (기존과 동일)\n",
    "#     print(\"2단계: unstructured로 문서 구조 분석 중 (hi_res 전략 사용)...\")\n",
    "#     elements = partition_pdf(filename=pdf_path, infer_table_structure=True, strategy=\"hi_res\")\n",
    "\n",
    "#     # 3단계: 요소 순회하며 최종 마크다운 및 데이터 생성\n",
    "#     print(\"3단계: 텍스트, 테이블, 이미지를 통합하고 AI로 내용을 보강합니다...\")\n",
    "#     final_markdown_parts = []\n",
    "#     extracted_tables = []\n",
    "#     extracted_images = []\n",
    "#     page_counters = defaultdict(lambda: {'tables': 0, 'images': 0})\n",
    "\n",
    "#     for el in elements:\n",
    "#         page_num = el.metadata.page_number\n",
    "        \n",
    "#         if \"unstructured.documents.elements.Table\" in str(type(el)):\n",
    "#             table_index = page_counters[page_num]['tables']\n",
    "#             if table_index < len(tables_by_page[page_num]):\n",
    "#                 # camelot이 추출한 DataFrame을 처리\n",
    "#                 raw_table_df = tables_by_page[page_num][table_index]\n",
    "#                 table_data = process_table_with_ai_camelot(raw_table_df, output_dir, page_num, table_index)\n",
    "#                 if table_data:\n",
    "#                     placeholder = f\"\\n\\n[[-- TABLE: Page {page_num}, Index {table_index} | Path: {table_data['path']} --]]\\n**표 요약:** {table_data['description']}\\n\\n\"\n",
    "#                     final_markdown_parts.append(placeholder)\n",
    "#                     extracted_tables.append(table_data)\n",
    "#                     page_counters[page_num]['tables'] += 1\n",
    "            \n",
    "#         elif \"unstructured.documents.elements.Image\" in str(type(el)):\n",
    "#             image_index = page_counters[page_num]['images']\n",
    "#             if image_index < len(images_by_page[page_num]):\n",
    "#                 # pdfplumber가 추출한 이미지 처리\n",
    "#                 raw_image_data = images_by_page[page_num][image_index]\n",
    "#                 image_data = process_image_with_ai(raw_image_data, output_dir, page_num, image_index)\n",
    "#                 if image_data:\n",
    "#                     relative_path = os.path.relpath(image_data['path'], output_dir).replace(os.sep, '/')\n",
    "#                     md_link = f\"\\n\\n![{image_data['description']}]({relative_path})\\n\\n\"\n",
    "#                     final_markdown_parts.append(md_link)\n",
    "#                     extracted_images.append(image_data)\n",
    "#                     page_counters[page_num]['images'] += 1\n",
    "        \n",
    "#         else:\n",
    "#             final_markdown_parts.append(el.text)\n",
    "\n",
    "#     # 4단계: 최종 결과 정리 및 저장 (기존과 동일)\n",
    "#     print(\"4단계: 최종 결과 정리 및 저장...\")\n",
    "#     final_markdown = \"\\n\\n\".join(final_markdown_parts)\n",
    "#     output_filename = os.path.join(output_dir, \"integrated_markdown_camelot.md\")\n",
    "#     with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(final_markdown)\n",
    "    \n",
    "#     print(\"\\n--- 작업 완료 ---\")\n",
    "#     return {\n",
    "#         \"output_dir\": output_dir,\n",
    "#         \"integrated_markdown_file\": output_filename,\n",
    "#         \"images\": extracted_images,\n",
    "#         \"tables\": extracted_tables,\n",
    "#         \"integrated_markdown_content\": final_markdown,\n",
    "#     }\n",
    "\n",
    "# # --- 코드 실행 예제 ---\n",
    "# pdf_path = \"datasets/manual.pdf\" # 실제 PDF 파일 경로로 변경해주세요.\n",
    "# extracted_data = create_integrated_markdown_from_camelot(pdf_path)\n",
    "\n",
    "# # # 결과 확인\n",
    "# # print(f\"\\nAI 요약/설명이 포함된 통합 마크다운 파일이 '{extracted_data['integrated_markdown_file']}'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "654289a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content=\"# Ⅴ 사업비 집행 및 정산지침\\n\\n## 1 사업비 지급 및 집행기간\\n\\n### □ 사업비 지급\\n\\n> 최고의 데이터 분석가로서 요청하신 CSV 데이터를 구조적으로 분석하고, 비전문가도 이해하기 쉽게 핵심 내용을 요약한 보고서를 작성해 드립니다.\\n> \\n> ---\\n> \\n> ## 데이터 분석 보고서: 분기별/회차별 자금 지급 현황\\n> \\n> ### 1. 표의 주제\\n> \\n> 이 표는 총 4회차에 걸쳐 지급되는 자금의 **분기별 신청 시기 및 해당 시점의 지급 비율**을 나타내는 데이터입니다.\\n> \\n> ### 2. 구조 설명\\n> \\n> *   이 데이터는 총 4개의 행(row)으로 구성되어 있으며, 상위 3개 행이 컬럼 헤더 역할을 합니다.\\n> *   **첫 번째 행**: 자금 지급이 이루어지는 **전체 분기**를 `1~2분기`와 `3~4분기`로 크게 구분합니다.\\n> *   **두 번째 행**: 각 분기 내에서 자금이 지급되는 **회차**를 `1회차`, `2회차`, `3회차`, `4회차`로 구분합니다.\\n> *   **세 번째 행**: 각 회차별로 **`신청 시기`**와 **`지급 비율`**이라는 구체적인 지표를 명시합니다.\\n> *   **네 번째 행**: 첫 번째부터 세 번째 행까지의 정보가 결합된 최종 조건에 대한 **실제 데이터 값**이 담겨 있습니다.\\n>     *   예를 들어, 첫 번째 열은 '1~2분기'의 '1회차'에 해당하는 '신청 시기'를, 두 번째 열은 그 '지급 비율'을 나타냅니다.\\n> \\n> ### 3. 핵심 정보 및 수치\\n> \\n> 이 데이터를 통해 파악할 수 있는 핵심 내용은 다음과 같습니다.\\n> \\n> 1.  **총 4회차의 자금 지급**: 제공된 데이터는 총 4번에 걸쳐 자금이 지급될 예정임을 보여줍니다.\\n> 2.  **가장 높은 지급 비율은 2회차**: 전체 지급 비율 중 가장 높은 46%는 '1~2분기'의 '2회차'에 배정되어 있으며, 이는 '협약 체결 후 2개월 이내' 신청 시 지급됩니다.\\n> 3.  **가장 낮은 지급 비율은 3회차**: 가장 낮은 지급 비율은 '3~4분기'의 '3회차'에 해당하는 9%입니다. 이 자금은 '중간 평가 후 1개월 이내'에 신청해야 지급됩니다.\\n> 4.  **상반기에 집중된 자금 지급**: 전체 자금의 상당 부분인 **66% (1회차 20% + 2회차 46%)**가 1~2분기(상반기)에 집중되어 지급됩니다. 반면, 3~4분기(하반기)에는 34% (3회차 9% + 4회차 25%)가 지급됩니다.\\n> \\n> ### 4. 패턴 또는 특이사항\\n> \\n> *   **초기 자금 투입 집중**: 데이터는 사업 초기 단계(상반기, 특히 2회차)에 가장 많은 자금이 투입되도록 설계되었음을 명확히 보여줍니다. 이는 사업의 빠른 궤도 진입 및 초반 동력 확보에 중점을 둔 자금 배분 전략으로 해석될 수 있습니다.\\n> *   **중간 평가와 연계된 소액 지급**: 3회차의 지급 비율이 9%로 현저히 낮은 점은 특이합니다. 이는 '중간 평가 후'라는 조건과 결합되어 있어, 중간 성과 검토 후 소액의 운영 자금 또는 특정 목표 달성 인센티브 형태로 지급될 가능성을 시사합니다.\"),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content='※ 지급비율은 변동될 수 있으며, 중간평가 결과에 따라 3회차부터 지급을 유예할 수 있음\\n\\n### □ 사업비 집행기간'),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content='○ ’24. 1. 1. ~ ’24. 12. 31.※ 동 기간 이외의 사용금액은 불인정 금액으로 간주하고 전액 반납해야 함※ 단, 집행기간 연장에 대해서 사전 승인을 받을 시에는 그 기한까지는 인정\\n\\n## 2 사업비 계좌관리 및 사용원칙\\n\\n### □ 사업비 계좌관리'),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content='○ (별도 계좌개설 필수) 각 지원 대상자는 당해 랩 운영지원금과민간부담금을 관리하는 통장(법인명의)을 주관·참여기관 별로 각각개설하고, 해당 계좌와 연계된 연구비카드(KCA)만 개설하여 사용\\n\\n### □ 사업비 사용원칙'),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content='○ 총사업비는 당초 제시했던 사업계획에 따른 집행을 원칙으로 함'),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content='○ 원천징수 신고납부 대상인 인건비성 수당의 경우, 소득세 등을원천징수하고 나머지 차액을 수령인의 계좌에 송금하여야 하며,원천징수한 소득세 등은 제작비로 인정함(원천징수지급조서 작성 첨부)\\n\\n_- 15 -_'),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content='○ 부가가치세, 관세 등 사후 환급이나 공제받을 수 있는 금액은 집행금액에서제외함을 원칙으로 하되, 사후 환급이 불가능한 경우에는 예외로 함'),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content='○ 보조금의 적정한 사용을 위하여 프로젝트와 관련 없는 집행과 제한업종 가맹점 등에서는 전용 사업비 카드를 사용할 수 없음'),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content='○ 선정 랩의 임직원(직계존비속을 포함) 등이 운영하는 업체 또는단체 계열 관계에 있는 업체 또는 단체와는 거래할 수 없음※ 컨소시엄 간 계약 불가'),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content='○ 보조금이 투명하고 효율적인 집행을 위하여 수요물자 구매나 시설공사계약을체결할 때 아래의 금액에 한하여 조달청(나라장터 등)을 이용해야 함\\n\\n- 2천만원을 초과하는 물품 및 용역 구매\\n\\n- 2억원을 초과하는 시설공사 계약'),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content='○ 모든 증빙서류는 사업기간 종료 후 5년간 보관해야 하며, 협회가요구할시 즉시 응하여야 함'),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content=\"○ 정부지원금은 콘텐츠 제작 관련 이외의 용도로 사용할 수 없음\\n\\n< 정부지원금 사용 불가항목 >\\n\\n> ## 데이터 분석 보고서: ICT 사업 비용 불인정 기준\\n> \\n> 이 보고서는 주어진 CSV 데이터를 분석하여 ICT 사업과 관련된 비용 불인정 기준에 대한 핵심 내용을 비전문가도 이해하기 쉽게 요약합니다.\\n> \\n> ---\\n> \\n> ### 1. 표의 주제\\n> \\n> 이 표는 ICT 사업 수행 시 비용으로 인정되지 않는 항목(불인정 기준)들을 요약하여 보여줍니다.\\n> \\n> ### 2. 구조 설명\\n> \\n> *   **총 행(Row) 개수**: 4개\\n> *   **총 열(Column) 개수**: 2개 (명목상 '0', '1'로 표시)\\n> \\n> 이 표는 총 4개의 행과 2개의 열로 구성되어 있습니다. 각 행은 ICT 사업에서 비용으로 인정되지 않는 특정 항목들을 나열합니다. 왼쪽 열(0번 열)과 오른쪽 열(1번 열)은 각각 다른 불인정 비용 항목을 제시하고 있습니다. 특히, 마지막 행의 오른쪽 열에 있는 'o 이외 ICT사업 비목별 불인정 기준'은 이 표에 제시된 모든 내용이 ICT 사업과 관련하여 비용으로 인정되지 않는 기준들을 설명하고 있음을 나타내는 포괄적인 제목 또는 분류입니다.\\n> \\n> ### 3. 핵심 정보 및 수치\\n> \\n> 1.  **목적 명확화**: 이 데이터는 ICT 사업 운영 시 경비로 인정받을 수 없는 총 6가지 구체적인 항목들을 명시하고 있습니다. 이는 회계 처리 또는 비용 청구 시 주의해야 할 불인정 기준을 안내하는 자료로 보입니다.\\n> 2.  **주요 불인정 항목**: 불인정되는 주요 비용으로는 `유흥업소 등에서의 사용금액`, `술/담배 등 기호상품에 대한 사용`, `사업과 관련 없는 자체보유 저작권료`와 같이 사업 목적과 무관하거나 개인적 성격이 강한 비용들이 포함됩니다.\\n> 3.  **이중 혜택 방지**: `관세, 부가세 등 환급이나 공제받는 금액`은 이미 다른 형태로 혜택을 받았으므로, 이중으로 비용으로 인정받을 수 없음을 명확히 합니다. 이는 중복 혜택을 방지하기 위한 기준입니다.\\n> 4.  **사업 관련성 기준**: `본 사업의 목적과 관련 없는 공간 임차료`나 `유류비 사용`, `자가시설 이용료, 감가상각비` 등은 해당 비용이 사업과의 직접적인 관련성이 부족하거나, 이미 자체적으로 처리 가능한 부분으로 판단되어 불인정될 수 있음을 시사합니다.\\n> \\n> ### 4. 패턴 또는 특이사항\\n> \\n> 1.  **구조적 특이점**: 마지막 행의 오른쪽 열에 위치한 'o 이외 ICT사업 비목별 불인정 기준'은 일반적인 데이터 값이 아닌, 해당 표 전체가 다루는 내용의 **포괄적인 제목 또는 카테고리 설명**으로 사용되고 있습니다. 이는 데이터 구조가 매우 압축적이거나, 목록 형태로 제공될 때 나타나는 특이한 방식입니다.\\n> 2.  **일관된 불인정 기준**: 제시된 모든 항목들은 `사업과 관련 없는`, `환급이나 공제받는`, `기호상품` 등 **'비용으로 인정되지 않는'이라는 명확한 기준**을 일관되게 보여줍니다. 이는 ICT 사업에서 투명하고 합리적인 비용 처리를 유도하기 위한 정책적 의도가 반영된 것으로 해석될 수 있습니다.\\n> \\n> ---\"),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content='※ 주관기관, 참여기관 사업비 편성 시 여비는 각 기관별로 산출하여 편성해야 함'),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content='○ 모든 지출은 지출 원인행위 및 지출결과에 대해 증빙할 수 있는증빙서류가 구비 되어야 하며, 지출목적이 합당한 경우에만 인정함※ [붙임] ICT사업 사업비 산정 및 정산 등에 관한 기준 및 세부내용 참조\\n\\n_- 16 -_\\n\\n# 3 인건비 편성\\n\\n## □ 인건비 편성\\n\\n### ○ 아래 랩 참여인력별 등급 및 월 임금기준에 따라 참여인력 인건비 지원\\n\\n- 참여인력 중 대학 및 대학원 교수 직위자들은 인건비 지급을 불인정하고그 외 참여인력에 대해서는 100%까지 인정\\n\\n### 예) 1) 교수 직위자'),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content=\"※ 지원대학(기업) 교수 직위자의 인건비는 불인정2) 그 외 참여 인력(박사과정의 경우)※ 월 임금 3,000,000원 기준 : 과제 참여율 50%(1,500,000원)로 편성할 경우, 편성된참여율의 100%(1,500,000원)까지 인정\\n\\n### < 랩 참여인력별 등급 및 월 임금기준* >\\n\\n> 최고의 데이터 분석가로서 주어진 CSV 데이터를 비전문가도 이해하기 쉽게 구조적으로 분석한 보고서입니다.\\n> \\n> ---\\n> \\n> ## 데이터 분석 보고서\\n> \\n> ### 1. 표의 주제\\n> \\n> 이 표는 특정 직무 또는 연구 참여 등급(학위 수준)별 월별 임금 기준과 그에 따른 자격 요건을 정의한 데이터입니다.\\n> \\n> ### 2. 구조 설명\\n> \\n> *   **각 행(Row):** 각 행은 '박사후연구원', '박사과정', '석사과정', '학사과정'과 같이 특정 학위 수준 또는 직무 등급을 나타냅니다.\\n> *   **각 열(Column):** 각 열은 해당 등급에 대한 구체적인 정보를 담고 있습니다.\\n>     *   **'등 급' 열:** 해당 직위 또는 학위 수준을 명시합니다.\\n>     *   **'월 임금 (100%참여율 기준)' 열:** 해당 등급의 월별 최소 임금 기준을 나타내며, 이는 100% 참여율을 기준으로 합니다.\\n>     *   **'자 격 기 준' 열:** 해당 등급에 필요한 학위 소지 여부, 전문 지식 수준, 그리고 수행해야 할 주요 업무 내용을 구체적으로 설명합니다.\\n> \\n> ### 3. 핵심 정보 및 수치\\n> \\n> 1.  **최고 등급의 임금 기준 차이:** '박사후연구원'의 월 임금은 '소속기관 인건비 지급기준'을 따르며, 이는 다른 학위 과정과 달리 고정된 최소 금액이 아닌 소속된 기관의 내부 규정에 의해 결정됩니다.\\n> 2.  **학위 수준별 최소 월 임금:** 학위 과정별 최소 월 임금은 명확한 차이를 보입니다.\\n>     *   '박사과정'은 월 3,000,000원 이상\\n>     *   '석사과정'은 월 2,200,000원 이상\\n>     *   '학사과정'은 월 1,300,000원 이상\\n>     이는 학위 수준이 높아질수록 임금 기준도 상승하는 경향을 보여줍니다.\\n> 3.  **공통된 핵심 업무:** '학사과정'을 제외한 모든 등급(박사후연구원, 박사과정, 석사과정)은 '콘텐츠 사업' 및 'R&D' 역할 수행을 핵심 자격 요건으로 명시하고 있습니다. 이는 해당 조직의 주요 업무가 연구 개발 및 콘텐츠 관련 프로젝트에 집중되어 있음을 시사합니다.\\n> 4.  **학사과정의 추가 역할:** '학사과정'은 '콘텐츠 사업 및 R&D 수행' 외에도 '회계, 정산, 예산 등 업무처리'를 수행할 수 있는 자격을 명시하고 있어, 다른 등급과 달리 연구 외적인 행정 및 지원 업무도 담당할 수 있음을 나타냅니다.\\n> \\n> ### 4. 패턴 또는 특이사항\\n> \\n> *   **임금과 학위의 정비례 관계:** '박사후연구원'을 제외하면, 제시된 최소 월 임금은 학위 수준이 높을수록 높아지는 명확한 패턴을 보입니다. 이는 전문성과 학력에 따른 보상 체계가 확립되어 있음을 보여줍니다.\\n> *   **조직의 핵심 역량 집중:** 대부분의 등급이 콘텐츠 사업 및 R&D 수행을 주요 역할로 하고 있어, 이 조직의 핵심 역량이 연구 개발 및 창작 활동에 있음을 짐작할 수 있습니다.\\n> *   **박사후연구원의 유연한 임금 체계:** '박사후연구원'의 임금 기준이 특정 금액이 아닌 '소속기관 인건비 지급기준'으로 명시된 것은 특이사항입니다. 이는 박사후연구원이 외부 기관과의 협력 또는 유동적인 프로젝트 단위로 참여할 가능성을 시사하며, 표준화된 직원보다는 전문 계약직의 특성을 가질 수 있음을 나타냅니다.\\n> *   **학사과정의 다재다능함:** '학사과정'은 연구 보조 역할과 더불어 회계, 정산 등의 행정 업무까지도 수행할 수 있음을 명시하여, 단순 연구 참여자를 넘어선 포괄적인 지원 인력으로 활용될 수 있음을 보여줍니다.\"),\n",
      " Document(metadata={'source': 'upstage_output\\\\output_with_descriptions.md', 'type': 'text'}, page_content='※ 통합과정의 경우 학사, 석사, 박사과정의 기준을 고려하여 소속기관의 장이 별도로정한 금액으로 월 임금 기준 편성※ 본 인건비 기준단가는 참여율 100%로 산정한 것이며, 참여율을 달리하는 경우 증감하여 적용* 국가연구개발사업 연구개발비 사용기준 제 40조(정부출연기관 학생인건비 사용기준) 준용\\n\\n_- 17 -_')]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "from pprint import pprint\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document  # Document 클래스를 import 합니다.\n",
    "\n",
    "# --- 1. 메타데이터를 포함하여 청킹하고 Document 객체를 생성하는 함수 ---\n",
    "\n",
    "def create_documents_from_markdown(markdown_content, source_path):\n",
    "    \"\"\"\n",
    "    논리적 청킹을 수행하고, 각 청크를 메타데이터가 포함된 LangChain Document 객체로 변환합니다.\n",
    "\n",
    "    Args:\n",
    "        markdown_content (str): 청킹할 마크다운 전체 텍스트\n",
    "        source_path (str): 원본 파일 경로 (메타데이터에 사용)\n",
    "\n",
    "    Returns:\n",
    "        list[Document]: 내용과 메타데이터가 포함된 Document 객체 리스트\n",
    "    \"\"\"\n",
    "    # 기존의 논리적 청킹 함수를 그대로 사용합니다.\n",
    "    text_chunks = chunk_markdown_logically(markdown_content)\n",
    "    \n",
    "    documents = []\n",
    "    for chunk_text in text_chunks:\n",
    "        metadata = {\"source\": source_path}  # 모든 청크에 기본 출처 정보 추가\n",
    "        \n",
    "        # 청크 내용을 기반으로 추가 메타데이터 파싱\n",
    "        if chunk_text.startswith(\"[[-- TABLE:\"):\n",
    "            metadata['type'] = 'table'\n",
    "            # 정규표현식을 사용하여 페이지 번호와 경로 추출\n",
    "            page_match = re.search(r\"Page (\\d+)\", chunk_text)\n",
    "            path_match = re.search(r\"Path: (.*?)\\s*--]]\", chunk_text)\n",
    "            if page_match:\n",
    "                metadata['page'] = int(page_match.group(1))\n",
    "            if path_match:\n",
    "                metadata['table_path'] = path_match.group(1).strip()\n",
    "\n",
    "        elif chunk_text.startswith(\"![\"):\n",
    "            metadata['type'] = 'image'\n",
    "            # 정규표현식을 사용하여 페이지 번호와 이미지 설명 추출\n",
    "            page_match = re.search(r\"Image from page (\\d+)\", chunk_text)\n",
    "            desc_match = re.search(r\"!\\[(.*?)\\]\\(\", chunk_text)\n",
    "            if page_match:\n",
    "                metadata['page'] = int(page_match.group(1))\n",
    "            if desc_match:\n",
    "                metadata['description'] = desc_match.group(1).strip()\n",
    "        else:\n",
    "            metadata['type'] = 'text'\n",
    "\n",
    "        # Document 객체 생성\n",
    "        doc = Document(page_content=chunk_text, metadata=metadata)\n",
    "        documents.append(doc)\n",
    "        \n",
    "    return documents\n",
    "\n",
    "# --- 2. 기존 로직 실행 및 all_chunks 생성 ---\n",
    "\n",
    "# chunk_markdown_logically 함수는 제공된 코드에 이미 정의되어 있다고 가정합니다.\n",
    "def chunk_markdown_logically(markdown_content):\n",
    "    \"\"\"\n",
    "    문서의 구조(제목, 표, 이미지)를 이해하여 논리적인 단위로 청킹합니다.\n",
    "    RAG 시스템에 가장 효과적인 방법입니다.\n",
    "    \"\"\"\n",
    "    # 1. 기본 블록으로 분리\n",
    "    blocks = markdown_content.split('\\n\\n')\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for block in blocks:\n",
    "        block = block.strip()\n",
    "        if not block:\n",
    "            continue\n",
    "\n",
    "        # 2. 규칙에 따라 청크 생성\n",
    "        is_table_placeholder = block.startswith(\"[[-- TABLE:\")\n",
    "        is_image_link = block.startswith(\"![\")\n",
    "        # 제목으로 사용될 수 있는 패턴들 (필요에 따라 추가)\n",
    "        is_heading = block.startswith(('□', '○', '※')) or re.match(r'^[0-9]+\\s|^\\w+\\s', block) and len(block) < 50\n",
    "\n",
    "        if is_table_placeholder or is_image_link:\n",
    "            # 테이블/이미지는 독립적인 청크로 처리\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            chunks.append(block)\n",
    "            current_chunk = \"\"\n",
    "        elif is_heading:\n",
    "            # 제목은 다음 블록과 합치기 위해, 진행 중인 청크를 먼저 저장\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = block\n",
    "        else:\n",
    "            # 일반 텍스트는 현재 청크(제목 또는 이전 텍스트)에 추가\n",
    "            if current_chunk:\n",
    "                current_chunk += \"\\n\\n\" + block\n",
    "            else:\n",
    "                current_chunk = block\n",
    "    \n",
    "    # 마지막 남은 청크 추가\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "        \n",
    "    return chunks\n",
    "\n",
    "source_file_path = \"upstage_output\\output_with_descriptions.md\"\n",
    "\n",
    "with open(source_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# 'all_chunks' 변수는 이제 단순 문자열 리스트가 아닌,\n",
    "# 내용과 메타데이터를 모두 포함한 Document 객체의 리스트가 됩니다.\n",
    "all_chunks = create_documents_from_markdown(content, source_file_path)\n",
    "\n",
    "pprint(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17e88c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# Ⅴ 사업비 집행 및 정산지침\\n\\n## 1 사업비 지급 및 집행기간\\n\\n### □ 사업비 지급',\n",
      " '> 최고의 데이터 분석가로서 요청하신 CSV 데이터를 구조적으로 분석하고, 비전문가도 이해하기 쉽게 핵심 내용을 요약한 보고서를 작성해 '\n",
      " '드립니다.\\n'\n",
      " '> \\n'\n",
      " '> ---\\n'\n",
      " '> \\n'\n",
      " '> ## 데이터 분석 보고서: 분기별/회차별 자금 지급 현황\\n'\n",
      " '> \\n'\n",
      " '> ### 1. 표의 주제\\n'\n",
      " '> \\n'\n",
      " '> 이 표는 총 4회차에 걸쳐 지급되는 자금의 **분기별 신청 시기 및 해당 시점의 지급 비율**을 나타내는 데이터입니다.\\n'\n",
      " '> \\n'\n",
      " '> ### 2. 구조 설명\\n'\n",
      " '> \\n'\n",
      " '> *   이 데이터는 총 4개의 행(row)으로 구성되어 있으며, 상위 3개 행이 컬럼 헤더 역할을 합니다.\\n'\n",
      " '> *   **첫 번째 행**: 자금 지급이 이루어지는 **전체 분기**를 `1~2분기`와 `3~4분기`로 크게 구분합니다.\\n'\n",
      " '> *   **두 번째 행**: 각 분기 내에서 자금이 지급되는 **회차**를 `1회차`, `2회차`, `3회차`, `4회차`로 '\n",
      " '구분합니다.',\n",
      " '> *   **두 번째 행**: 각 분기 내에서 자금이 지급되는 **회차**를 `1회차`, `2회차`, `3회차`, `4회차`로 '\n",
      " '구분합니다.\\n'\n",
      " '> *   **세 번째 행**: 각 회차별로 **`신청 시기`**와 **`지급 비율`**이라는 구체적인 지표를 명시합니다.\\n'\n",
      " '> *   **네 번째 행**: 첫 번째부터 세 번째 행까지의 정보가 결합된 최종 조건에 대한 **실제 데이터 값**이 담겨 있습니다.\\n'\n",
      " \">     *   예를 들어, 첫 번째 열은 '1~2분기'의 '1회차'에 해당하는 '신청 시기'를, 두 번째 열은 그 '지급 비율'을 \"\n",
      " '나타냅니다.\\n'\n",
      " '> \\n'\n",
      " '> ### 3. 핵심 정보 및 수치\\n'\n",
      " '> \\n'\n",
      " '> 이 데이터를 통해 파악할 수 있는 핵심 내용은 다음과 같습니다.\\n'\n",
      " '> \\n'\n",
      " '> 1.  **총 4회차의 자금 지급**: 제공된 데이터는 총 4번에 걸쳐 자금이 지급될 예정임을 보여줍니다.',\n",
      " '> \\n'\n",
      " '> 1.  **총 4회차의 자금 지급**: 제공된 데이터는 총 4번에 걸쳐 자금이 지급될 예정임을 보여줍니다.\\n'\n",
      " \"> 2.  **가장 높은 지급 비율은 2회차**: 전체 지급 비율 중 가장 높은 46%는 '1~2분기'의 '2회차'에 배정되어 있으며, \"\n",
      " \"이는 '협약 체결 후 2개월 이내' 신청 시 지급됩니다.\\n\"\n",
      " \"> 3.  **가장 낮은 지급 비율은 3회차**: 가장 낮은 지급 비율은 '3~4분기'의 '3회차'에 해당하는 9%입니다. 이 자금은 \"\n",
      " \"'중간 평가 후 1개월 이내'에 신청해야 지급됩니다.\\n\"\n",
      " '> 4.  **상반기에 집중된 자금 지급**: 전체 자금의 상당 부분인 **66% (1회차 20% + 2회차 46%)**가 '\n",
      " '1~2분기(상반기)에 집중되어 지급됩니다. 반면, 3~4분기(하반기)에는 34% (3회차 9% + 4회차 25%)가 지급됩니다.\\n'\n",
      " '> \\n'\n",
      " '> ### 4. 패턴 또는 특이사항\\n'\n",
      " '>',\n",
      " '> \\n'\n",
      " '> ### 4. 패턴 또는 특이사항\\n'\n",
      " '> \\n'\n",
      " '> *   **초기 자금 투입 집중**: 데이터는 사업 초기 단계(상반기, 특히 2회차)에 가장 많은 자금이 투입되도록 설계되었음을 '\n",
      " '명확히 보여줍니다. 이는 사업의 빠른 궤도 진입 및 초반 동력 확보에 중점을 둔 자금 배분 전략으로 해석될 수 있습니다.\\n'\n",
      " \"> *   **중간 평가와 연계된 소액 지급**: 3회차의 지급 비율이 9%로 현저히 낮은 점은 특이합니다. 이는 '중간 평가 후'라는 \"\n",
      " '조건과 결합되어 있어, 중간 성과 검토 후 소액의 운영 자금 또는 특정 목표 달성 인센티브 형태로 지급될 가능성을 시사합니다.',\n",
      " '※ 지급비율은 변동될 수 있으며, 중간평가 결과에 따라 3회차부터 지급을 유예할 수 있음\\n'\n",
      " '\\n'\n",
      " '### □ 사업비 집행기간\\n'\n",
      " '\\n'\n",
      " '○ ’24. 1. 1. ~ ’24. 12. 31.※ 동 기간 이외의 사용금액은 불인정 금액으로 간주하고 전액 반납해야 함※ 단, 집행기간 '\n",
      " '연장에 대해서 사전 승인을 받을 시에는 그 기한까지는 인정\\n'\n",
      " '\\n'\n",
      " '## 2 사업비 계좌관리 및 사용원칙\\n'\n",
      " '\\n'\n",
      " '### □ 사업비 계좌관리\\n'\n",
      " '\\n'\n",
      " '○ (별도 계좌개설 필수) 각 지원 대상자는 당해 랩 운영지원금과민간부담금을 관리하는 통장(법인명의)을 주관·참여기관 별로 각각개설하고, '\n",
      " '해당 계좌와 연계된 연구비카드(KCA)만 개설하여 사용\\n'\n",
      " '\\n'\n",
      " '### □ 사업비 사용원칙\\n'\n",
      " '\\n'\n",
      " '○ 총사업비는 당초 제시했던 사업계획에 따른 집행을 원칙으로 함\\n'\n",
      " '\\n'\n",
      " '○ 원천징수 신고납부 대상인 인건비성 수당의 경우, 소득세 등을원천징수하고 나머지 차액을 수령인의 계좌에 송금하여야 하며,원천징수한 '\n",
      " '소득세 등은 제작비로 인정함(원천징수지급조서 작성 첨부)\\n'\n",
      " '\\n'\n",
      " '_- 15 -_',\n",
      " '_- 15 -_\\n'\n",
      " '\\n'\n",
      " '○ 부가가치세, 관세 등 사후 환급이나 공제받을 수 있는 금액은 집행금액에서제외함을 원칙으로 하되, 사후 환급이 불가능한 경우에는 예외로 '\n",
      " '함\\n'\n",
      " '\\n'\n",
      " '○ 보조금의 적정한 사용을 위하여 프로젝트와 관련 없는 집행과 제한업종 가맹점 등에서는 전용 사업비 카드를 사용할 수 없음\\n'\n",
      " '\\n'\n",
      " '○ 선정 랩의 임직원(직계존비속을 포함) 등이 운영하는 업체 또는단체 계열 관계에 있는 업체 또는 단체와는 거래할 수 없음※ 컨소시엄 간 '\n",
      " '계약 불가\\n'\n",
      " '\\n'\n",
      " '○ 보조금이 투명하고 효율적인 집행을 위하여 수요물자 구매나 시설공사계약을체결할 때 아래의 금액에 한하여 조달청(나라장터 등)을 이용해야 '\n",
      " '함\\n'\n",
      " '\\n'\n",
      " '- 2천만원을 초과하는 물품 및 용역 구매\\n'\n",
      " '\\n'\n",
      " '- 2억원을 초과하는 시설공사 계약\\n'\n",
      " '\\n'\n",
      " '○ 모든 증빙서류는 사업기간 종료 후 5년간 보관해야 하며, 협회가요구할시 즉시 응하여야 함\\n'\n",
      " '\\n'\n",
      " '○ 정부지원금은 콘텐츠 제작 관련 이외의 용도로 사용할 수 없음\\n'\n",
      " '\\n'\n",
      " '< 정부지원금 사용 불가항목 >',\n",
      " '> ## 데이터 분석 보고서: ICT 사업 비용 불인정 기준\\n'\n",
      " '> \\n'\n",
      " '> 이 보고서는 주어진 CSV 데이터를 분석하여 ICT 사업과 관련된 비용 불인정 기준에 대한 핵심 내용을 비전문가도 이해하기 쉽게 '\n",
      " '요약합니다.\\n'\n",
      " '> \\n'\n",
      " '> ---\\n'\n",
      " '> \\n'\n",
      " '> ### 1. 표의 주제\\n'\n",
      " '> \\n'\n",
      " '> 이 표는 ICT 사업 수행 시 비용으로 인정되지 않는 항목(불인정 기준)들을 요약하여 보여줍니다.\\n'\n",
      " '> \\n'\n",
      " '> ### 2. 구조 설명\\n'\n",
      " '> \\n'\n",
      " '> *   **총 행(Row) 개수**: 4개\\n'\n",
      " \"> *   **총 열(Column) 개수**: 2개 (명목상 '0', '1'로 표시)\\n\"\n",
      " '>',\n",
      " '> \\n'\n",
      " '> ### 2. 구조 설명\\n'\n",
      " '> \\n'\n",
      " '> *   **총 행(Row) 개수**: 4개\\n'\n",
      " \"> *   **총 열(Column) 개수**: 2개 (명목상 '0', '1'로 표시)\\n\"\n",
      " '> \\n'\n",
      " '> 이 표는 총 4개의 행과 2개의 열로 구성되어 있습니다. 각 행은 ICT 사업에서 비용으로 인정되지 않는 특정 항목들을 나열합니다. '\n",
      " \"왼쪽 열(0번 열)과 오른쪽 열(1번 열)은 각각 다른 불인정 비용 항목을 제시하고 있습니다. 특히, 마지막 행의 오른쪽 열에 있는 'o \"\n",
      " \"이외 ICT사업 비목별 불인정 기준'은 이 표에 제시된 모든 내용이 ICT 사업과 관련하여 비용으로 인정되지 않는 기준들을 설명하고 \"\n",
      " '있음을 나타내는 포괄적인 제목 또는 분류입니다.\\n'\n",
      " '> \\n'\n",
      " '> ### 3. 핵심 정보 및 수치\\n'\n",
      " '> \\n'\n",
      " '> 1.  **목적 명확화**: 이 데이터는 ICT 사업 운영 시 경비로 인정받을 수 없는 총 6가지 구체적인 항목들을 명시하고 '\n",
      " '있습니다. 이는 회계 처리 또는 비용 청구 시 주의해야 할 불인정 기준을 안내하는 자료로 보입니다.',\n",
      " '> 2.  **주요 불인정 항목**: 불인정되는 주요 비용으로는 `유흥업소 등에서의 사용금액`, `술/담배 등 기호상품에 대한 사용`, '\n",
      " '`사업과 관련 없는 자체보유 저작권료`와 같이 사업 목적과 무관하거나 개인적 성격이 강한 비용들이 포함됩니다.\\n'\n",
      " '> 3.  **이중 혜택 방지**: `관세, 부가세 등 환급이나 공제받는 금액`은 이미 다른 형태로 혜택을 받았으므로, 이중으로 비용으로 '\n",
      " '인정받을 수 없음을 명확히 합니다. 이는 중복 혜택을 방지하기 위한 기준입니다.\\n'\n",
      " '> 4.  **사업 관련성 기준**: `본 사업의 목적과 관련 없는 공간 임차료`나 `유류비 사용`, `자가시설 이용료, 감가상각비` '\n",
      " '등은 해당 비용이 사업과의 직접적인 관련성이 부족하거나, 이미 자체적으로 처리 가능한 부분으로 판단되어 불인정될 수 있음을 시사합니다.\\n'\n",
      " '> \\n'\n",
      " '> ### 4. 패턴 또는 특이사항\\n'\n",
      " '>',\n",
      " '> \\n'\n",
      " '> ### 4. 패턴 또는 특이사항\\n'\n",
      " '> \\n'\n",
      " \"> 1.  **구조적 특이점**: 마지막 행의 오른쪽 열에 위치한 'o 이외 ICT사업 비목별 불인정 기준'은 일반적인 데이터 값이 \"\n",
      " '아닌, 해당 표 전체가 다루는 내용의 **포괄적인 제목 또는 카테고리 설명**으로 사용되고 있습니다. 이는 데이터 구조가 매우 '\n",
      " '압축적이거나, 목록 형태로 제공될 때 나타나는 특이한 방식입니다.\\n'\n",
      " \"> 2.  **일관된 불인정 기준**: 제시된 모든 항목들은 `사업과 관련 없는`, `환급이나 공제받는`, `기호상품` 등 **'비용으로 \"\n",
      " \"인정되지 않는'이라는 명확한 기준**을 일관되게 보여줍니다. 이는 ICT 사업에서 투명하고 합리적인 비용 처리를 유도하기 위한 정책적 \"\n",
      " '의도가 반영된 것으로 해석될 수 있습니다.\\n'\n",
      " '> \\n'\n",
      " '> ---',\n",
      " '※ 주관기관, 참여기관 사업비 편성 시 여비는 각 기관별로 산출하여 편성해야 함\\n'\n",
      " '\\n'\n",
      " '○ 모든 지출은 지출 원인행위 및 지출결과에 대해 증빙할 수 있는증빙서류가 구비 되어야 하며, 지출목적이 합당한 경우에만 인정함※ '\n",
      " '[붙임] ICT사업 사업비 산정 및 정산 등에 관한 기준 및 세부내용 참조\\n'\n",
      " '\\n'\n",
      " '_- 16 -_\\n'\n",
      " '\\n'\n",
      " '# 3 인건비 편성\\n'\n",
      " '\\n'\n",
      " '## □ 인건비 편성\\n'\n",
      " '\\n'\n",
      " '### ○ 아래 랩 참여인력별 등급 및 월 임금기준에 따라 참여인력 인건비 지원\\n'\n",
      " '\\n'\n",
      " '- 참여인력 중 대학 및 대학원 교수 직위자들은 인건비 지급을 불인정하고그 외 참여인력에 대해서는 100%까지 인정\\n'\n",
      " '\\n'\n",
      " '### 예) 1) 교수 직위자\\n'\n",
      " '\\n'\n",
      " '※ 지원대학(기업) 교수 직위자의 인건비는 불인정2) 그 외 참여 인력(박사과정의 경우)※ 월 임금 3,000,000원 기준 : 과제 '\n",
      " '참여율 50%(1,500,000원)로 편성할 경우, 편성된참여율의 100%(1,500,000원)까지 인정\\n'\n",
      " '\\n'\n",
      " '### < 랩 참여인력별 등급 및 월 임금기준* >',\n",
      " '> 최고의 데이터 분석가로서 주어진 CSV 데이터를 비전문가도 이해하기 쉽게 구조적으로 분석한 보고서입니다.\\n'\n",
      " '> \\n'\n",
      " '> ---\\n'\n",
      " '> \\n'\n",
      " '> ## 데이터 분석 보고서\\n'\n",
      " '> \\n'\n",
      " '> ### 1. 표의 주제\\n'\n",
      " '> \\n'\n",
      " '> 이 표는 특정 직무 또는 연구 참여 등급(학위 수준)별 월별 임금 기준과 그에 따른 자격 요건을 정의한 데이터입니다.\\n'\n",
      " '> \\n'\n",
      " '> ### 2. 구조 설명\\n'\n",
      " '> \\n'\n",
      " \"> *   **각 행(Row):** 각 행은 '박사후연구원', '박사과정', '석사과정', '학사과정'과 같이 특정 학위 수준 또는 직무 \"\n",
      " '등급을 나타냅니다.\\n'\n",
      " '> *   **각 열(Column):** 각 열은 해당 등급에 대한 구체적인 정보를 담고 있습니다.\\n'\n",
      " \">     *   **'등 급' 열:** 해당 직위 또는 학위 수준을 명시합니다.\\n\"\n",
      " \">     *   **'월 임금 (100%참여율 기준)' 열:** 해당 등급의 월별 최소 임금 기준을 나타내며, 이는 100% 참여율을 \"\n",
      " '기준으로 합니다.',\n",
      " \">     *   **'월 임금 (100%참여율 기준)' 열:** 해당 등급의 월별 최소 임금 기준을 나타내며, 이는 100% 참여율을 \"\n",
      " '기준으로 합니다.\\n'\n",
      " \">     *   **'자 격 기 준' 열:** 해당 등급에 필요한 학위 소지 여부, 전문 지식 수준, 그리고 수행해야 할 주요 업무 \"\n",
      " '내용을 구체적으로 설명합니다.\\n'\n",
      " '> \\n'\n",
      " '> ### 3. 핵심 정보 및 수치\\n'\n",
      " '> \\n'\n",
      " \"> 1.  **최고 등급의 임금 기준 차이:** '박사후연구원'의 월 임금은 '소속기관 인건비 지급기준'을 따르며, 이는 다른 학위 \"\n",
      " '과정과 달리 고정된 최소 금액이 아닌 소속된 기관의 내부 규정에 의해 결정됩니다.\\n'\n",
      " '> 2.  **학위 수준별 최소 월 임금:** 학위 과정별 최소 월 임금은 명확한 차이를 보입니다.\\n'\n",
      " \">     *   '박사과정'은 월 3,000,000원 이상\\n\"\n",
      " \">     *   '석사과정'은 월 2,200,000원 이상\\n\"\n",
      " \">     *   '학사과정'은 월 1,300,000원 이상\",\n",
      " \">     *   '석사과정'은 월 2,200,000원 이상\\n\"\n",
      " \">     *   '학사과정'은 월 1,300,000원 이상\\n\"\n",
      " '>     이는 학위 수준이 높아질수록 임금 기준도 상승하는 경향을 보여줍니다.\\n'\n",
      " \"> 3.  **공통된 핵심 업무:** '학사과정'을 제외한 모든 등급(박사후연구원, 박사과정, 석사과정)은 '콘텐츠 사업' 및 'R&D' \"\n",
      " '역할 수행을 핵심 자격 요건으로 명시하고 있습니다. 이는 해당 조직의 주요 업무가 연구 개발 및 콘텐츠 관련 프로젝트에 집중되어 있음을 '\n",
      " '시사합니다.\\n'\n",
      " \"> 4.  **학사과정의 추가 역할:** '학사과정'은 '콘텐츠 사업 및 R&D 수행' 외에도 '회계, 정산, 예산 등 업무처리'를 \"\n",
      " '수행할 수 있는 자격을 명시하고 있어, 다른 등급과 달리 연구 외적인 행정 및 지원 업무도 담당할 수 있음을 나타냅니다.\\n'\n",
      " '> \\n'\n",
      " '> ### 4. 패턴 또는 특이사항\\n'\n",
      " '>',\n",
      " '> \\n'\n",
      " '> ### 4. 패턴 또는 특이사항\\n'\n",
      " '> \\n'\n",
      " \"> *   **임금과 학위의 정비례 관계:** '박사후연구원'을 제외하면, 제시된 최소 월 임금은 학위 수준이 높을수록 높아지는 명확한 \"\n",
      " '패턴을 보입니다. 이는 전문성과 학력에 따른 보상 체계가 확립되어 있음을 보여줍니다.\\n'\n",
      " '> *   **조직의 핵심 역량 집중:** 대부분의 등급이 콘텐츠 사업 및 R&D 수행을 주요 역할로 하고 있어, 이 조직의 핵심 역량이 '\n",
      " '연구 개발 및 창작 활동에 있음을 짐작할 수 있습니다.\\n'\n",
      " \"> *   **박사후연구원의 유연한 임금 체계:** '박사후연구원'의 임금 기준이 특정 금액이 아닌 '소속기관 인건비 지급기준'으로 \"\n",
      " '명시된 것은 특이사항입니다. 이는 박사후연구원이 외부 기관과의 협력 또는 유동적인 프로젝트 단위로 참여할 가능성을 시사하며, 표준화된 '\n",
      " '직원보다는 전문 계약직의 특성을 가질 수 있음을 나타냅니다.',\n",
      " \"> *   **학사과정의 다재다능함:** '학사과정'은 연구 보조 역할과 더불어 회계, 정산 등의 행정 업무까지도 수행할 수 있음을 \"\n",
      " '명시하여, 단순 연구 참여자를 넘어선 포괄적인 지원 인력으로 활용될 수 있음을 보여줍니다.',\n",
      " '※ 통합과정의 경우 학사, 석사, 박사과정의 기준을 고려하여 소속기관의 장이 별도로정한 금액으로 월 임금 기준 편성※ 본 인건비 '\n",
      " '기준단가는 참여율 100%로 산정한 것이며, 참여율을 달리하는 경우 증감하여 적용* 국가연구개발사업 연구개발비 사용기준 제 '\n",
      " '40조(정부출연기관 학생인건비 사용기준) 준용\\n'\n",
      " '\\n'\n",
      " '_- 17 -_']\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "with open(source_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=100, \n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "# .split_text() 메서드를 사용하여 텍스트를 분할합니다.\n",
    "split_texts = text_splitter.split_text(file_content)\n",
    "pprint(split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26501f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Vector Store 생성 시작 ---\n",
      "임베딩 모델을 위한 디바이스 설정: cuda\n",
      "\n",
      "--- Vector Store 생성 및 저장 완료 ---\n",
      "'./chroma_db' 디렉토리에 16개의 청크가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Vector Store 생성 및 저장 ---\n",
    "\n",
    "print(\"\\n--- Vector Store 생성 시작 ---\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"임베딩 모델을 위한 디바이스 설정: {device}\")\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"dragonkue/BGE-m3-ko\",\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'normalize_embeddings': True},\n",
    ")\n",
    "\n",
    "# Chroma.from_documents 함수는 Document 객체 리스트를 받도록 설계되어 있습니다.\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_db\"  # DB를 저장할 디렉토리\n",
    ")\n",
    "\n",
    "print(\"\\n--- Vector Store 생성 및 저장 완료 ---\")\n",
    "print(f\"'{vectorstore._persist_directory}' 디렉토리에 {len(all_chunks)}개의 청크가 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c968cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If the user asks for a simple answer, summarize the key points.\n",
    "If the question is unrelated to the context in the regulations, respond with \"관련 정보를 찾을 수 없습니다.\"\n",
    "Answer in Korean.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "# llm = OllamaLLM(model=\"gemma3:4b\")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25eb37da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2회차 지급 비율은 46%이며, 협약 체결 후 2개월 이내 신청 시 지급됩니다.\n"
     ]
    }
   ],
   "source": [
    "question = \"2회차 지급 비율과 지급 시기는?\"\n",
    "# 테이블 정보를 최대한 정밀하게 추출할 수 있도록 하기\n",
    "answer = chain.invoke(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5faf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90963807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
